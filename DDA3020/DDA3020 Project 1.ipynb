{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train_data = pd.read_csv('linear_regression_train(2).txt', delimiter=r\"\\s+|,\", engine='python', header=None)\n",
    "test_data = pd.read_csv('linear_regression_test(2).txt', delimiter=r\"\\s+|,\", engine='python', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:, :-1].values\n",
    "y_train = train_data.iloc[:, -1].values\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias (w0): 3.613646026669057\n",
      "w1: 0.015325690386245282\n",
      "w2: 0.00025227640634062354\n",
      "w3: 0.0007203868499650188\n",
      "w4: 0.9991635645789793\n",
      "w5: 0.9997402360310111\n",
      "w6: 1.0006233993583653\n",
      "w7: 0.9988323588429907\n",
      "w8: 1.0000013015236566\n",
      "w9: 1.0002245483558714\n",
      "w10: 0.9990396151482023\n",
      "w11: 0.9993448460859428\n",
      "\n",
      "Predicted y values for the test set:\n",
      "Test Sample 1: -56.11129687958479\n",
      "Test Sample 2: -173.51651970931792\n",
      "Test Sample 3: -6.770877912227151\n",
      "Test Sample 4: 209.517090441872\n",
      "Test Sample 5: 116.89029785098526\n",
      "Test Sample 6: -100.29084527235767\n",
      "Test Sample 7: -310.12783900144876\n",
      "Test Sample 8: 501.3863019426081\n",
      "Test Sample 9: 244.1147678085642\n",
      "Test Sample 10: 18.566393254550192\n"
     ]
    }
   ],
   "source": [
    "# 初始化和训练模型\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 提取模型的偏置 (w0) 和系数 (w1, ..., w11)\n",
    "w0 = model.intercept_\n",
    "coefficients = model.coef_\n",
    "\n",
    "print(f\"Bias (w0): {w0}\")\n",
    "for idx, coef in enumerate(coefficients, start=1):\n",
    "    print(f\"w{idx}: {coef}\")\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 打印测试集的预测结果\n",
    "print(\"\\nPredicted y values for the test set:\")\n",
    "for i, pred in enumerate(y_pred, start=1):\n",
    "    print(f\"Test Sample {i}: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias (w0): 3.6136460266688557\n",
      "w1: 0.015325690386246638\n",
      "w2: 0.0002522764063409254\n",
      "w3: 0.0007203868499652336\n",
      "w4: 0.9991635645789788\n",
      "w5: 0.9997402360310117\n",
      "w6: 1.000623399358362\n",
      "w7: 0.99883235884299\n",
      "w8: 1.0000013015236562\n",
      "w9: 1.0002245483558732\n",
      "w10: 0.9990396151482013\n",
      "w11: 0.9993448460859436\n",
      "\n",
      "Predicted y values for the test set (manual calculation):\n",
      "Test Sample 1: -56.11129687958453\n",
      "Test Sample 2: -173.5165197093183\n",
      "Test Sample 3: -6.770877912227066\n",
      "Test Sample 4: 209.51709044187174\n",
      "Test Sample 5: 116.89029785098508\n",
      "Test Sample 6: -100.29084527235786\n",
      "Test Sample 7: -310.1278390014489\n",
      "Test Sample 8: 501.38630194260753\n",
      "Test Sample 9: 244.11476780856378\n",
      "Test Sample 10: 18.566393254550302\n"
     ]
    }
   ],
   "source": [
    "# 在 X_train 中添加一列全为 1 的列，作为偏置项\n",
    "X_train_b = np.hstack((np.ones((X_train.shape[0], 1)), X_train))  # 维度: (2024, 12)\n",
    "X_test_b = np.hstack((np.ones((X_test.shape[0], 1)), X_test))    # 维度: (10, 12)\n",
    "\n",
    "# 根据正则方程计算系数 w_hat\n",
    "XtX = np.dot(X_train_b.T, X_train_b)\n",
    "XtX_inv = np.linalg.inv(XtX)  # 求逆矩阵\n",
    "Xt_y = np.dot(X_train_b.T, y_train)\n",
    "w_hat = np.dot(XtX_inv, Xt_y)  # 维度: (12, )\n",
    "\n",
    "# 提取偏置和系数\n",
    "w0_manual = w_hat[0]\n",
    "coefficients_manual = w_hat[1:]\n",
    "\n",
    "print(f\"Bias (w0): {w0_manual}\")\n",
    "for idx, coef in enumerate(coefficients_manual, start=1):\n",
    "    print(f\"w{idx}: {coef}\")\n",
    "\n",
    "# 使用手动计算的模型进行预测\n",
    "y_pred_manual = np.dot(X_test_b, w_hat)\n",
    "\n",
    "# 打印预测结果\n",
    "print(\"\\nPredicted y values for the test set (manual calculation):\")\n",
    "for i, pred in enumerate(y_pred_manual, start=1):\n",
    "    print(f\"Test Sample {i}: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_excel('Classification iris(2).xlsx')\n",
    "\n",
    "# 初始化训练集和测试集的列表\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "\n",
    "# 按类别分组\n",
    "grouped = df.groupby('class')\n",
    "\n",
    "for class_name, group in grouped:\n",
    "    n_samples = len(group)\n",
    "    n_train = floor(0.7 * n_samples)\n",
    "    \n",
    "    # 获取前70%的实例ID作为训练集\n",
    "    train_ids.extend(group.iloc[:n_train]['instance_id'].tolist())\n",
    "    \n",
    "    # 获取剩余30%的实例ID作为测试集\n",
    "    test_ids.extend(group.iloc[n_train:]['instance_id'].tolist())\n",
    "\n",
    "print(\"Q2.2.1  Split training set and test set:\")\n",
    "print(f\"Training set: {train_ids}\")\n",
    "print(f\"Test set: {test_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别获取训练集和测试集的数据\n",
    "train_df = df[df['instance_id'].isin(train_ids)].reset_index(drop=True)\n",
    "test_df = df[df['instance_id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "# 特征和标签\n",
    "X_train = train_df[['sepal length', 'sepal width', 'petal length', 'petal width']].values  # 105x4\n",
    "y_train = train_df['class'].values  # 105x1\n",
    "\n",
    "X_test = test_df[['sepal length', 'sepal width', 'petal length', 'petal width']].values  # 45x4\n",
    "y_test = test_df['class'].values    # 45x1\n",
    "\n",
    "# 标签编码（将类别标签转换为数值）\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# 获取所有类别\n",
    "classes = le.classes_\n",
    "\n",
    "# 生成字典存储每个class的模型、weight、b、支持向量索引\n",
    "classifiers = {}\n",
    "w_dict = {}\n",
    "b_dict = {}\n",
    "support_vectors_dict = {}\n",
    "\n",
    "# 训练每个类别的SVM模型\n",
    "for idx, cls in enumerate(classes):\n",
    "\n",
    "    # 创建二分类标签：当前类别为1，其他类别为-1\n",
    "    y_train_binary = np.where(y_train_encoded == idx, 1, -1)  # 105x1\n",
    "    y_test_binary = np.where(y_test_encoded == idx, 1, -1)  # 45x1\n",
    "\n",
    "    # 初始化SVM模型（linear，C=1e5模拟硬间隔）\n",
    "    clf = SVC(kernel='linear', C=1e5)\n",
    "    clf.fit(X_train, y_train_binary)\n",
    "    \n",
    "    # 存储模型参数\n",
    "    classifiers[cls] = clf\n",
    "    w_dict[cls] = clf.coef_[0].tolist()\n",
    "    b_dict[cls] = clf.intercept_[0]\n",
    "    support_vectors_dict[cls] = clf.support_.tolist()\n",
    "\n",
    "\n",
    "# 为每个样本记录每个分类器的预测得分\n",
    "train_predictions = np.zeros((X_train.shape[0], len(classes)))  # 训练集得分\n",
    "test_predictions = np.zeros((X_test.shape[0], len(classes)))    # 测试集得分\n",
    "\n",
    "for idx, cls in enumerate(classes):\n",
    "    clf = classifiers[cls]\n",
    "    train_predictions[:, idx] = clf.decision_function(X_train)\n",
    "    test_predictions[:, idx] = clf.decision_function(X_test)\n",
    "\n",
    "# 对每个样本选择得分最高的类作为预测结果\n",
    "train_pred_final = le.inverse_transform(np.argmax(train_predictions, axis=1))  # axis=1: 按行\n",
    "test_pred_final = le.inverse_transform(np.argmax(test_predictions, axis=1))\n",
    "\n",
    "# 计算总错误率\n",
    "total_train_error = np.sum(train_pred_final != y_train) / len(y_train)\n",
    "total_test_error = np.sum(test_pred_final != y_test) / len(y_test)\n",
    "\n",
    "# 计算每个小组的错误率\n",
    "def calculate_group_errors(y_true, y_pred, classes):\n",
    "    group_errors = {}\n",
    "    for cls in classes:\n",
    "        # 获取属于当前类别的样本\n",
    "        cls_mask = (y_true == cls)\n",
    "        total = np.sum(cls_mask)\n",
    "        # 计算错误率\n",
    "        errors = np.sum(y_pred[cls_mask] != cls)\n",
    "        error_rate = errors / total\n",
    "        group_errors[cls] = error_rate\n",
    "    return group_errors\n",
    "\n",
    "group_train_errors = calculate_group_errors(y_train, train_pred_final, classes)\n",
    "group_test_errors = calculate_group_errors(y_test, test_pred_final, classes)\n",
    "\n",
    "# 确定哪些类别在训练集上是线性可分的（训练错误为0）\n",
    "linear_separable = [cls for cls in classes if group_train_errors[cls] == 0]\n",
    "\n",
    "# 打印结果\n",
    "print(\"\\nQ2.2.2 Calculation using Standard SVM Model:\")\n",
    "print(f\"total training error: {total_train_error}, total testing error: {total_test_error},\")\n",
    "print()\n",
    "\n",
    "for cls in classes:\n",
    "    print(f\"class {cls}:\")\n",
    "    print(f\"training error: {group_train_errors[cls]}, testing error: {group_test_errors[cls]},\")\n",
    "    print(f\"w: [{', '.join(map(str, w_dict[cls]))}], b: {b_dict[cls]},\")\n",
    "    print(f\"support vector indices: [{', '.join(map(str, support_vectors_dict[cls]))}],\")\n",
    "    # 输出空一行\n",
    "    print()\n",
    "\n",
    "print(f\"Linear separable classes: {', '.join(linear_separable)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义C的值\n",
    "C_values = [0.25 * t for t in range(1, 5)]\n",
    "\n",
    "print('\\nQ2.2.3 Calculation using SVM with Slack Variables (C=0.25×t, where t=1,...,4):')\n",
    "\n",
    "for C in C_values:\n",
    "    print(\"\\n-------------------------------------------\")\n",
    "    print(f\"C={C},\")\n",
    "    \n",
    "    # 生成字典存储每个class的模型、weight、b、支持向量索引和错误率\n",
    "    classifiers = {}\n",
    "    w_dict = {}\n",
    "    b_dict = {}\n",
    "    support_vectors_dict = {}\n",
    "    class_slack_vars = {}\n",
    "    \n",
    "    # 训练每个类别的SVM模型\n",
    "    for idx, cls in enumerate(classes):\n",
    "        # 创建二分类标签：当前类别为1，其他类别为-1\n",
    "        y_train_binary = np.where(y_train_encoded == idx, 1, -1)\n",
    "        y_test_binary = np.where(y_test_encoded == idx, 1, -1)\n",
    "        \n",
    "        # 初始化SVM模型（线性核，C为当前值）\n",
    "        clf = SVC(kernel='linear', C=C)\n",
    "        clf.fit(X_train, y_train_binary)\n",
    "        \n",
    "        # 存储模型参数\n",
    "        classifiers[cls] = clf\n",
    "        w_dict[cls] = clf.coef_[0].tolist()\n",
    "        b_dict[cls] = clf.intercept_[0]\n",
    "        support_vectors_dict[cls] = clf.support_.tolist()\n",
    "\n",
    "        # 计算支持向量的松弛变量ζ\n",
    "        support_indices = clf.support_\n",
    "        support_vectors = X_train[support_indices]\n",
    "        support_labels = y_train_binary[support_indices]\n",
    "        decision_values = clf.decision_function(support_vectors)\n",
    "        slack_vars = np.maximum(0, 1 - support_labels * decision_values)\n",
    "        class_slack_vars[cls] = slack_vars.tolist()\n",
    "    \n",
    "    # 为每个样本记录每个分类器的预测得分\n",
    "    train_predictions = np.zeros((X_train.shape[0], len(classes)))  # 训练集得分\n",
    "    test_predictions = np.zeros((X_test.shape[0], len(classes)))    # 测试集得分\n",
    "    \n",
    "    for idx, cls in enumerate(classes):\n",
    "        clf = classifiers[cls]\n",
    "        train_predictions[:, idx] = clf.decision_function(X_train)\n",
    "        test_predictions[:, idx] = clf.decision_function(X_test)\n",
    "    \n",
    "    # 对每个样本选择得分最高的类作为预测结果\n",
    "    train_pred_final = le.inverse_transform(np.argmax(train_predictions, axis=1))  # axis=1: 按行\n",
    "    test_pred_final = le.inverse_transform(np.argmax(test_predictions, axis=1))\n",
    "    \n",
    "    # 计算总错误率\n",
    "    total_train_error = np.sum(train_pred_final != y_train) / len(y_train)\n",
    "    total_test_error = np.sum(test_pred_final != y_test) / len(y_test)\n",
    "    \n",
    "    # 计算每个小组的错误率\n",
    "    group_train_errors = calculate_group_errors(y_train, train_pred_final, classes)\n",
    "    group_test_errors = calculate_group_errors(y_test, test_pred_final, classes)\n",
    "    \n",
    "    print(f\"total training error: {total_train_error}, total testing error: {total_test_error},\")\n",
    "    print()\n",
    "    \n",
    "    for cls in classes:\n",
    "        print(f\"class {cls}:\")\n",
    "        print(f\"training error: {group_train_errors[cls]}, testing error: {group_test_errors[cls]},\")\n",
    "        print(f\"w: [{', '.join(map(str, w_dict[cls]))}], b: {b_dict[cls]},\")\n",
    "        print(f\"support vector indices: [{', '.join(map(str, support_vectors_dict[cls]))}],\")\n",
    "        print(f\"slack variable: {class_slack_vars[cls]},\")\n",
    "        print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 kernel 类型\n",
    "kernel_types = [\n",
    "    ('2nd-order Polynomial Kernel', 'poly', 2, 'scale'),\n",
    "    ('3rd-order Polynomial Kernel', 'poly', 3, 'scale'),\n",
    "    ('Radial Basis Function Kernel with σ = 1', 'rbf', None, 0.5),\n",
    "    ('Sigmoidal Kernel with σ = 1', 'sigmoid', None, 0.5)\n",
    "]\n",
    "\n",
    "print(\"\\nQ2.2.4 Calculation using SVM with Kernel Functions:\")\n",
    "\n",
    "for i, (description, kernel, degree, gamma) in enumerate(kernel_types, start=1):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(f\"({chr(96 + i)}) {description},\")\n",
    "    \n",
    "    # 生成字典存储每个class的模型、weight、b、支持向量索引\n",
    "    classifiers = {}\n",
    "    w_dict = {}\n",
    "    b_dict = {}\n",
    "    support_vectors_dict = {}\n",
    "    \n",
    "    # 训练每个类别的SVM模型\n",
    "    for idx, cls in enumerate(classes):\n",
    "        # 创建二分类标签：当前类别为1，其他类别为-1\n",
    "        y_train_binary = np.where(y_train_encoded == idx, 1, -1)\n",
    "        y_test_binary = np.where(y_test_encoded == idx, 1, -1)\n",
    "        \n",
    "        # 初始化SVM模型\n",
    "        if kernel == 'poly':\n",
    "            clf = SVC(kernel=kernel, degree=degree, gamma=gamma, C=1e5)\n",
    "        elif kernel == 'rbf':\n",
    "            clf = SVC(kernel=kernel, gamma=gamma, C=1e5)\n",
    "        elif kernel == 'sigmoid':\n",
    "            clf = SVC(kernel=kernel, gamma=1, C=1e5)  # Here we equate gamma to sigma (1)\n",
    "        else:  # 应对特殊情况\n",
    "            clf = SVC(kernel=kernel, C=1e5)\n",
    "        \n",
    "        # 训练SVM模型\n",
    "        clf.fit(X_train, y_train_binary)\n",
    "        \n",
    "        # 存储模型参数\n",
    "        classifiers[cls] = clf\n",
    "        if kernel == 'linear':\n",
    "            w = clf.coef_[0].tolist()\n",
    "        else:\n",
    "            w = ' '  # 非线性核的w设为' '\n",
    "        w_dict[cls] = w\n",
    "        b_dict[cls] = clf.intercept_[0]\n",
    "        support_vectors_dict[cls] = clf.support_.tolist()\n",
    "    \n",
    "    # 为每个样本记录每个分类器的预测得分\n",
    "    train_predictions = np.zeros((X_train.shape[0], len(classes)))  # 训练集得分\n",
    "    test_predictions = np.zeros((X_test.shape[0], len(classes)))    # 测试集得分\n",
    "    \n",
    "    for idx, cls in enumerate(classes):\n",
    "        clf = classifiers[cls]\n",
    "        train_predictions[:, idx] = clf.decision_function(X_train)\n",
    "        test_predictions[:, idx] = clf.decision_function(X_test)\n",
    "    \n",
    "    # 对每个样本选择得分最高的类作为预测结果\n",
    "    train_pred_final = le.inverse_transform(np.argmax(train_predictions, axis=1))  # axis=1: 按行\n",
    "    test_pred_final = le.inverse_transform(np.argmax(test_predictions, axis=1))\n",
    "    \n",
    "    # 计算总错误率\n",
    "    total_train_error = np.sum(train_pred_final != y_train) / len(y_train)\n",
    "    total_test_error = np.sum(test_pred_final != y_test) / len(y_test)\n",
    "    \n",
    "    # 计算每个小组的错误率\n",
    "    group_train_errors = calculate_group_errors(y_train, train_pred_final, classes)\n",
    "    group_test_errors = calculate_group_errors(y_test, test_pred_final, classes)\n",
    "    \n",
    "    print(f\"total training error: {total_train_error}, total testing error: {total_test_error},\")\n",
    "    print()\n",
    "    \n",
    "    for cls in classes:\n",
    "        print(f\"class {cls}:\")\n",
    "        print(f\"training error: {group_train_errors[cls]}, testing error: {group_test_errors[cls]},\")\n",
    "        print(f\"w: {w_dict[cls]}, b: {b_dict[cls]},\")\n",
    "        print(f\"support vector indices: {support_vectors_dict[cls]},\")\n",
    "        print()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
