{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.3 Questions for Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Data: CiteSeer()\n",
      "Graph Data: BZR(405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8p/_lylf4tn2yz39y4qkw9vg1jw0000gn/T/ipykernel_7944/3575513016.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  node_data = torch.load('node_data.pt')  # Assuming node_data is a PyG dataset\n",
      "/var/folders/8p/_lylf4tn2yz39y4qkw9vg1jw0000gn/T/ipykernel_7944/3575513016.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_data = torch.load('graph_data.pt')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Load the dataset\n",
    "node_data = torch.load('node_data.pt')  # Assuming node_data is a PyG dataset\n",
    "graph_data = torch.load('graph_data.pt')\n",
    "\n",
    "print(\"Node Data:\", node_data)\n",
    "print(\"Graph Data:\", graph_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 120\n",
      "Validation set size: 500\n",
      "Test set size: 1000\n"
     ]
    }
   ],
   "source": [
    "data = node_data\n",
    "\n",
    "# Output data split information\n",
    "print(f\"Training set size: {data.train_mask.sum().item()}\")\n",
    "print(f\"Validation set size: {data.val_mask.sum().item()}\")\n",
    "print(f\"Test set size: {data.test_mask.sum().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [16, 32, 64]  # candidate hidden layer dimensions\n",
    "learning_rates = [0.01, 0.005]  # candidate learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2-layer GCN...\n",
      "Epoch 1, Train Loss: 1.7802, Val Loss: 1.7117, Val Acc: 0.4720\n",
      "Epoch 2, Train Loss: 1.5492, Val Loss: 1.6132, Val Acc: 0.5660\n",
      "Epoch 3, Train Loss: 1.3065, Val Loss: 1.5025, Val Acc: 0.5960\n",
      "Epoch 4, Train Loss: 1.0738, Val Loss: 1.4020, Val Acc: 0.6200\n",
      "Epoch 5, Train Loss: 0.8400, Val Loss: 1.3153, Val Acc: 0.6400\n",
      "Epoch 6, Train Loss: 0.6616, Val Loss: 1.2406, Val Acc: 0.6500\n",
      "Epoch 7, Train Loss: 0.5233, Val Loss: 1.1768, Val Acc: 0.6600\n",
      "Epoch 8, Train Loss: 0.4251, Val Loss: 1.1235, Val Acc: 0.6700\n",
      "Epoch 9, Train Loss: 0.3106, Val Loss: 1.0830, Val Acc: 0.6860\n",
      "Epoch 10, Train Loss: 0.2442, Val Loss: 1.0533, Val Acc: 0.6780\n",
      "Epoch 11, Train Loss: 0.1713, Val Loss: 1.0373, Val Acc: 0.6880\n",
      "Epoch 12, Train Loss: 0.1445, Val Loss: 1.0304, Val Acc: 0.6820\n",
      "Epoch 13, Train Loss: 0.1145, Val Loss: 1.0301, Val Acc: 0.6720\n",
      "Epoch 14, Train Loss: 0.1042, Val Loss: 1.0354, Val Acc: 0.6620\n",
      "Epoch 15, Train Loss: 0.0817, Val Loss: 1.0457, Val Acc: 0.6580\n",
      "Epoch 16, Train Loss: 0.0638, Val Loss: 1.0567, Val Acc: 0.6560\n",
      "Epoch 17, Train Loss: 0.0481, Val Loss: 1.0690, Val Acc: 0.6560\n",
      "Epoch 18, Train Loss: 0.0467, Val Loss: 1.0841, Val Acc: 0.6560\n",
      "Epoch 19, Train Loss: 0.0396, Val Loss: 1.1009, Val Acc: 0.6580\n",
      "Epoch 20, Train Loss: 0.0271, Val Loss: 1.1184, Val Acc: 0.6540\n",
      "Epoch 21, Train Loss: 0.0286, Val Loss: 1.1373, Val Acc: 0.6540\n",
      "Epoch 22, Train Loss: 0.0245, Val Loss: 1.1520, Val Acc: 0.6460\n",
      "Epoch 23, Train Loss: 0.0246, Val Loss: 1.1660, Val Acc: 0.6440\n",
      "Epoch 24, Train Loss: 0.0264, Val Loss: 1.1772, Val Acc: 0.6420\n",
      "Epoch 25, Train Loss: 0.0228, Val Loss: 1.1894, Val Acc: 0.6420\n",
      "Epoch 26, Train Loss: 0.0145, Val Loss: 1.1997, Val Acc: 0.6400\n",
      "Epoch 27, Train Loss: 0.0109, Val Loss: 1.2096, Val Acc: 0.6380\n",
      "Epoch 28, Train Loss: 0.0167, Val Loss: 1.2197, Val Acc: 0.6360\n",
      "Epoch 29, Train Loss: 0.0127, Val Loss: 1.2307, Val Acc: 0.6380\n",
      "Epoch 30, Train Loss: 0.0137, Val Loss: 1.2410, Val Acc: 0.6400\n",
      "Epoch 31, Train Loss: 0.0074, Val Loss: 1.2509, Val Acc: 0.6420\n",
      "Epoch 32, Train Loss: 0.0145, Val Loss: 1.2628, Val Acc: 0.6440\n",
      "Epoch 33, Train Loss: 0.0080, Val Loss: 1.2758, Val Acc: 0.6400\n",
      "Epoch 34, Train Loss: 0.0084, Val Loss: 1.2883, Val Acc: 0.6380\n",
      "Epoch 35, Train Loss: 0.0093, Val Loss: 1.2981, Val Acc: 0.6380\n",
      "Epoch 36, Train Loss: 0.0061, Val Loss: 1.3072, Val Acc: 0.6360\n",
      "Epoch 37, Train Loss: 0.0110, Val Loss: 1.3150, Val Acc: 0.6360\n",
      "Epoch 38, Train Loss: 0.0059, Val Loss: 1.3226, Val Acc: 0.6360\n",
      "Epoch 39, Train Loss: 0.0041, Val Loss: 1.3296, Val Acc: 0.6340\n",
      "Epoch 40, Train Loss: 0.0060, Val Loss: 1.3365, Val Acc: 0.6340\n",
      "Epoch 41, Train Loss: 0.0045, Val Loss: 1.3417, Val Acc: 0.6340\n",
      "Epoch 42, Train Loss: 0.0057, Val Loss: 1.3456, Val Acc: 0.6360\n",
      "Epoch 43, Train Loss: 0.0066, Val Loss: 1.3482, Val Acc: 0.6360\n",
      "Epoch 44, Train Loss: 0.0126, Val Loss: 1.3518, Val Acc: 0.6380\n",
      "Epoch 45, Train Loss: 0.0045, Val Loss: 1.3558, Val Acc: 0.6400\n",
      "Epoch 46, Train Loss: 0.0035, Val Loss: 1.3598, Val Acc: 0.6460\n",
      "Epoch 47, Train Loss: 0.0033, Val Loss: 1.3638, Val Acc: 0.6440\n",
      "Epoch 48, Train Loss: 0.0033, Val Loss: 1.3671, Val Acc: 0.6440\n",
      "Epoch 49, Train Loss: 0.0043, Val Loss: 1.3703, Val Acc: 0.6440\n",
      "Epoch 50, Train Loss: 0.0067, Val Loss: 1.3747, Val Acc: 0.6460\n",
      "Epoch 51, Train Loss: 0.0030, Val Loss: 1.3798, Val Acc: 0.6440\n",
      "Epoch 52, Train Loss: 0.0026, Val Loss: 1.3846, Val Acc: 0.6420\n",
      "Epoch 53, Train Loss: 0.0031, Val Loss: 1.3904, Val Acc: 0.6440\n",
      "Epoch 54, Train Loss: 0.0024, Val Loss: 1.3962, Val Acc: 0.6460\n",
      "Epoch 55, Train Loss: 0.0052, Val Loss: 1.4014, Val Acc: 0.6460\n",
      "Epoch 56, Train Loss: 0.0030, Val Loss: 1.4057, Val Acc: 0.6460\n",
      "Epoch 57, Train Loss: 0.0041, Val Loss: 1.4078, Val Acc: 0.6460\n",
      "Epoch 58, Train Loss: 0.0032, Val Loss: 1.4097, Val Acc: 0.6460\n",
      "Epoch 59, Train Loss: 0.0057, Val Loss: 1.4127, Val Acc: 0.6460\n",
      "Epoch 60, Train Loss: 0.0017, Val Loss: 1.4153, Val Acc: 0.6440\n",
      "Epoch 61, Train Loss: 0.0024, Val Loss: 1.4175, Val Acc: 0.6440\n",
      "Epoch 62, Train Loss: 0.0031, Val Loss: 1.4194, Val Acc: 0.6440\n",
      "Epoch 63, Train Loss: 0.0044, Val Loss: 1.4210, Val Acc: 0.6440\n",
      "Epoch 64, Train Loss: 0.0043, Val Loss: 1.4216, Val Acc: 0.6440\n",
      "Epoch 65, Train Loss: 0.0023, Val Loss: 1.4222, Val Acc: 0.6440\n",
      "Epoch 66, Train Loss: 0.0027, Val Loss: 1.4226, Val Acc: 0.6420\n",
      "Epoch 67, Train Loss: 0.0045, Val Loss: 1.4225, Val Acc: 0.6420\n",
      "Epoch 68, Train Loss: 0.0020, Val Loss: 1.4224, Val Acc: 0.6480\n",
      "Epoch 69, Train Loss: 0.0017, Val Loss: 1.4225, Val Acc: 0.6480\n",
      "Epoch 70, Train Loss: 0.0017, Val Loss: 1.4230, Val Acc: 0.6480\n",
      "Epoch 71, Train Loss: 0.0039, Val Loss: 1.4253, Val Acc: 0.6480\n",
      "Epoch 72, Train Loss: 0.0026, Val Loss: 1.4285, Val Acc: 0.6480\n",
      "Epoch 73, Train Loss: 0.0017, Val Loss: 1.4317, Val Acc: 0.6460\n",
      "Epoch 74, Train Loss: 0.0024, Val Loss: 1.4355, Val Acc: 0.6460\n",
      "Epoch 75, Train Loss: 0.0035, Val Loss: 1.4402, Val Acc: 0.6420\n",
      "Epoch 76, Train Loss: 0.0016, Val Loss: 1.4449, Val Acc: 0.6440\n",
      "Epoch 77, Train Loss: 0.0017, Val Loss: 1.4493, Val Acc: 0.6460\n",
      "Epoch 78, Train Loss: 0.0014, Val Loss: 1.4535, Val Acc: 0.6460\n",
      "Epoch 79, Train Loss: 0.0027, Val Loss: 1.4577, Val Acc: 0.6460\n",
      "Epoch 80, Train Loss: 0.0036, Val Loss: 1.4604, Val Acc: 0.6480\n",
      "Epoch 81, Train Loss: 0.0029, Val Loss: 1.4639, Val Acc: 0.6500\n",
      "Epoch 82, Train Loss: 0.0018, Val Loss: 1.4672, Val Acc: 0.6480\n",
      "Epoch 83, Train Loss: 0.0019, Val Loss: 1.4700, Val Acc: 0.6480\n",
      "Epoch 84, Train Loss: 0.0017, Val Loss: 1.4720, Val Acc: 0.6480\n",
      "Epoch 85, Train Loss: 0.0017, Val Loss: 1.4736, Val Acc: 0.6480\n",
      "Epoch 86, Train Loss: 0.0011, Val Loss: 1.4748, Val Acc: 0.6480\n",
      "Epoch 87, Train Loss: 0.0028, Val Loss: 1.4763, Val Acc: 0.6500\n",
      "Epoch 88, Train Loss: 0.0033, Val Loss: 1.4766, Val Acc: 0.6500\n",
      "Epoch 89, Train Loss: 0.0017, Val Loss: 1.4774, Val Acc: 0.6500\n",
      "Epoch 90, Train Loss: 0.0014, Val Loss: 1.4779, Val Acc: 0.6500\n",
      "Epoch 91, Train Loss: 0.0033, Val Loss: 1.4775, Val Acc: 0.6500\n",
      "Epoch 92, Train Loss: 0.0021, Val Loss: 1.4774, Val Acc: 0.6460\n",
      "Epoch 93, Train Loss: 0.0017, Val Loss: 1.4780, Val Acc: 0.6480\n",
      "Epoch 94, Train Loss: 0.0027, Val Loss: 1.4795, Val Acc: 0.6460\n",
      "Epoch 95, Train Loss: 0.0013, Val Loss: 1.4812, Val Acc: 0.6460\n",
      "Epoch 96, Train Loss: 0.0022, Val Loss: 1.4826, Val Acc: 0.6460\n",
      "Epoch 97, Train Loss: 0.0007, Val Loss: 1.4841, Val Acc: 0.6500\n",
      "Epoch 98, Train Loss: 0.0023, Val Loss: 1.4854, Val Acc: 0.6500\n",
      "Epoch 99, Train Loss: 0.0009, Val Loss: 1.4865, Val Acc: 0.6500\n",
      "Epoch 100, Train Loss: 0.0012, Val Loss: 1.4875, Val Acc: 0.6500\n",
      "Best Epoch: 11, Train Loss: 0.1713, Val Loss: 1.0373, Val Acc: 0.6880\n",
      "Test Accuracy: 0.6550\n",
      "Training 2-layer MLP...\n",
      "Epoch 1, Train Loss: 1.7951, Val Loss: 1.7885, Val Acc: 0.2320\n",
      "Epoch 2, Train Loss: 1.7015, Val Loss: 1.7628, Val Acc: 0.2380\n",
      "Epoch 3, Train Loss: 1.5907, Val Loss: 1.7315, Val Acc: 0.3020\n",
      "Epoch 4, Train Loss: 1.4533, Val Loss: 1.6989, Val Acc: 0.3540\n",
      "Epoch 5, Train Loss: 1.3003, Val Loss: 1.6657, Val Acc: 0.3860\n",
      "Epoch 6, Train Loss: 1.1383, Val Loss: 1.6327, Val Acc: 0.3980\n",
      "Epoch 7, Train Loss: 0.9757, Val Loss: 1.5996, Val Acc: 0.4220\n",
      "Epoch 8, Train Loss: 0.8190, Val Loss: 1.5669, Val Acc: 0.4340\n",
      "Epoch 9, Train Loss: 0.6731, Val Loss: 1.5352, Val Acc: 0.4500\n",
      "Epoch 10, Train Loss: 0.5416, Val Loss: 1.5050, Val Acc: 0.4680\n",
      "Epoch 11, Train Loss: 0.4271, Val Loss: 1.4766, Val Acc: 0.4860\n",
      "Epoch 12, Train Loss: 0.3307, Val Loss: 1.4502, Val Acc: 0.4920\n",
      "Epoch 13, Train Loss: 0.2519, Val Loss: 1.4262, Val Acc: 0.5060\n",
      "Epoch 14, Train Loss: 0.1892, Val Loss: 1.4049, Val Acc: 0.5120\n",
      "Epoch 15, Train Loss: 0.1407, Val Loss: 1.3863, Val Acc: 0.5060\n",
      "Epoch 16, Train Loss: 0.1040, Val Loss: 1.3706, Val Acc: 0.5140\n",
      "Epoch 17, Train Loss: 0.0767, Val Loss: 1.3575, Val Acc: 0.5100\n",
      "Epoch 18, Train Loss: 0.0567, Val Loss: 1.3470, Val Acc: 0.5120\n",
      "Epoch 19, Train Loss: 0.0421, Val Loss: 1.3387, Val Acc: 0.5240\n",
      "Epoch 20, Train Loss: 0.0315, Val Loss: 1.3324, Val Acc: 0.5260\n",
      "Epoch 21, Train Loss: 0.0239, Val Loss: 1.3278, Val Acc: 0.5200\n",
      "Epoch 22, Train Loss: 0.0183, Val Loss: 1.3245, Val Acc: 0.5220\n",
      "Epoch 23, Train Loss: 0.0142, Val Loss: 1.3225, Val Acc: 0.5220\n",
      "Epoch 24, Train Loss: 0.0111, Val Loss: 1.3214, Val Acc: 0.5200\n",
      "Epoch 25, Train Loss: 0.0089, Val Loss: 1.3210, Val Acc: 0.5100\n",
      "Epoch 26, Train Loss: 0.0072, Val Loss: 1.3213, Val Acc: 0.5040\n",
      "Epoch 27, Train Loss: 0.0059, Val Loss: 1.3220, Val Acc: 0.5040\n",
      "Epoch 28, Train Loss: 0.0048, Val Loss: 1.3231, Val Acc: 0.5000\n",
      "Epoch 29, Train Loss: 0.0041, Val Loss: 1.3244, Val Acc: 0.5000\n",
      "Epoch 30, Train Loss: 0.0034, Val Loss: 1.3259, Val Acc: 0.5000\n",
      "Epoch 31, Train Loss: 0.0030, Val Loss: 1.3275, Val Acc: 0.5000\n",
      "Epoch 32, Train Loss: 0.0026, Val Loss: 1.3292, Val Acc: 0.4980\n",
      "Epoch 33, Train Loss: 0.0022, Val Loss: 1.3309, Val Acc: 0.4980\n",
      "Epoch 34, Train Loss: 0.0020, Val Loss: 1.3326, Val Acc: 0.5000\n",
      "Epoch 35, Train Loss: 0.0018, Val Loss: 1.3342, Val Acc: 0.5000\n",
      "Epoch 36, Train Loss: 0.0016, Val Loss: 1.3358, Val Acc: 0.4980\n",
      "Epoch 37, Train Loss: 0.0014, Val Loss: 1.3373, Val Acc: 0.4920\n",
      "Epoch 38, Train Loss: 0.0013, Val Loss: 1.3387, Val Acc: 0.4920\n",
      "Epoch 39, Train Loss: 0.0012, Val Loss: 1.3401, Val Acc: 0.4920\n",
      "Epoch 40, Train Loss: 0.0011, Val Loss: 1.3414, Val Acc: 0.4920\n",
      "Epoch 41, Train Loss: 0.0010, Val Loss: 1.3425, Val Acc: 0.4920\n",
      "Epoch 42, Train Loss: 0.0010, Val Loss: 1.3436, Val Acc: 0.4940\n",
      "Epoch 43, Train Loss: 0.0009, Val Loss: 1.3446, Val Acc: 0.4940\n",
      "Epoch 44, Train Loss: 0.0009, Val Loss: 1.3456, Val Acc: 0.4920\n",
      "Epoch 45, Train Loss: 0.0008, Val Loss: 1.3464, Val Acc: 0.4920\n",
      "Epoch 46, Train Loss: 0.0008, Val Loss: 1.3472, Val Acc: 0.4920\n",
      "Epoch 47, Train Loss: 0.0007, Val Loss: 1.3479, Val Acc: 0.4920\n",
      "Epoch 48, Train Loss: 0.0007, Val Loss: 1.3486, Val Acc: 0.4920\n",
      "Epoch 49, Train Loss: 0.0007, Val Loss: 1.3491, Val Acc: 0.4940\n",
      "Epoch 50, Train Loss: 0.0007, Val Loss: 1.3497, Val Acc: 0.4940\n",
      "Epoch 51, Train Loss: 0.0006, Val Loss: 1.3501, Val Acc: 0.4920\n",
      "Epoch 52, Train Loss: 0.0006, Val Loss: 1.3505, Val Acc: 0.4920\n",
      "Epoch 53, Train Loss: 0.0006, Val Loss: 1.3509, Val Acc: 0.4920\n",
      "Epoch 54, Train Loss: 0.0006, Val Loss: 1.3512, Val Acc: 0.4900\n",
      "Epoch 55, Train Loss: 0.0006, Val Loss: 1.3515, Val Acc: 0.4900\n",
      "Epoch 56, Train Loss: 0.0006, Val Loss: 1.3517, Val Acc: 0.4920\n",
      "Epoch 57, Train Loss: 0.0005, Val Loss: 1.3520, Val Acc: 0.4940\n",
      "Epoch 58, Train Loss: 0.0005, Val Loss: 1.3522, Val Acc: 0.4940\n",
      "Epoch 59, Train Loss: 0.0005, Val Loss: 1.3523, Val Acc: 0.4940\n",
      "Epoch 60, Train Loss: 0.0005, Val Loss: 1.3524, Val Acc: 0.4940\n",
      "Epoch 61, Train Loss: 0.0005, Val Loss: 1.3526, Val Acc: 0.4940\n",
      "Epoch 62, Train Loss: 0.0005, Val Loss: 1.3527, Val Acc: 0.4940\n",
      "Epoch 63, Train Loss: 0.0005, Val Loss: 1.3527, Val Acc: 0.4940\n",
      "Epoch 64, Train Loss: 0.0005, Val Loss: 1.3528, Val Acc: 0.4940\n",
      "Epoch 65, Train Loss: 0.0005, Val Loss: 1.3528, Val Acc: 0.4940\n",
      "Epoch 66, Train Loss: 0.0005, Val Loss: 1.3529, Val Acc: 0.4940\n",
      "Epoch 67, Train Loss: 0.0005, Val Loss: 1.3529, Val Acc: 0.4940\n",
      "Epoch 68, Train Loss: 0.0005, Val Loss: 1.3529, Val Acc: 0.4940\n",
      "Epoch 69, Train Loss: 0.0005, Val Loss: 1.3529, Val Acc: 0.4940\n",
      "Epoch 70, Train Loss: 0.0005, Val Loss: 1.3529, Val Acc: 0.4940\n",
      "Epoch 71, Train Loss: 0.0004, Val Loss: 1.3529, Val Acc: 0.4940\n",
      "Epoch 72, Train Loss: 0.0004, Val Loss: 1.3528, Val Acc: 0.4940\n",
      "Epoch 73, Train Loss: 0.0004, Val Loss: 1.3528, Val Acc: 0.4940\n",
      "Epoch 74, Train Loss: 0.0004, Val Loss: 1.3528, Val Acc: 0.4920\n",
      "Epoch 75, Train Loss: 0.0004, Val Loss: 1.3528, Val Acc: 0.4940\n",
      "Epoch 76, Train Loss: 0.0004, Val Loss: 1.3527, Val Acc: 0.4920\n",
      "Epoch 77, Train Loss: 0.0004, Val Loss: 1.3527, Val Acc: 0.4920\n",
      "Epoch 78, Train Loss: 0.0004, Val Loss: 1.3526, Val Acc: 0.4920\n",
      "Epoch 79, Train Loss: 0.0004, Val Loss: 1.3526, Val Acc: 0.4920\n",
      "Epoch 80, Train Loss: 0.0004, Val Loss: 1.3525, Val Acc: 0.4920\n",
      "Epoch 81, Train Loss: 0.0004, Val Loss: 1.3525, Val Acc: 0.4920\n",
      "Epoch 82, Train Loss: 0.0004, Val Loss: 1.3524, Val Acc: 0.4940\n",
      "Epoch 83, Train Loss: 0.0004, Val Loss: 1.3524, Val Acc: 0.4940\n",
      "Epoch 84, Train Loss: 0.0004, Val Loss: 1.3523, Val Acc: 0.4940\n",
      "Epoch 85, Train Loss: 0.0004, Val Loss: 1.3523, Val Acc: 0.4940\n",
      "Epoch 86, Train Loss: 0.0004, Val Loss: 1.3522, Val Acc: 0.4920\n",
      "Epoch 87, Train Loss: 0.0004, Val Loss: 1.3522, Val Acc: 0.4920\n",
      "Epoch 88, Train Loss: 0.0004, Val Loss: 1.3521, Val Acc: 0.4920\n",
      "Epoch 89, Train Loss: 0.0004, Val Loss: 1.3521, Val Acc: 0.4920\n",
      "Epoch 90, Train Loss: 0.0004, Val Loss: 1.3520, Val Acc: 0.4920\n",
      "Epoch 91, Train Loss: 0.0004, Val Loss: 1.3520, Val Acc: 0.4920\n",
      "Epoch 92, Train Loss: 0.0004, Val Loss: 1.3519, Val Acc: 0.4920\n",
      "Epoch 93, Train Loss: 0.0004, Val Loss: 1.3518, Val Acc: 0.4920\n",
      "Epoch 94, Train Loss: 0.0004, Val Loss: 1.3518, Val Acc: 0.4920\n",
      "Epoch 95, Train Loss: 0.0004, Val Loss: 1.3517, Val Acc: 0.4920\n",
      "Epoch 96, Train Loss: 0.0004, Val Loss: 1.3517, Val Acc: 0.4920\n",
      "Epoch 97, Train Loss: 0.0004, Val Loss: 1.3517, Val Acc: 0.4920\n",
      "Epoch 98, Train Loss: 0.0004, Val Loss: 1.3516, Val Acc: 0.4920\n",
      "Epoch 99, Train Loss: 0.0004, Val Loss: 1.3516, Val Acc: 0.4920\n",
      "Epoch 100, Train Loss: 0.0004, Val Loss: 1.3515, Val Acc: 0.4920\n",
      "Best Epoch: 20, Train Loss: 0.0315, Val Loss: 1.3324, Val Acc: 0.5260\n",
      "Test Accuracy: 0.5200\n",
      "2-layer GCN Test Accuracy: 0.6550\n",
      "2-layer MLP Test Accuracy: 0.5200\n",
      "GCN outperforms MLP because it utilizes graph structure information by aggregating neighbor nodes, capturing local relationships. In contrast, MLP only relies on node features, ignoring the graph's connectivity, which limits its ability to model interactions between nodes\n"
     ]
    }
   ],
   "source": [
    "# Define GCN\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define MLP\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Training\n",
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index) if isinstance(model, GCN) else model(data.x)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    # print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Verification\n",
    "def validate(model, data, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index) if isinstance(model, GCN) else model(data.x)\n",
    "        loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "        pred = out.argmax(dim=1)\n",
    "        # print(\"----------------------\")\n",
    "        correct = (pred[data.val_mask] == data.y[data.val_mask]).sum().item()\n",
    "        total = data.val_mask.sum().item()\n",
    "        acc = correct / total\n",
    "        # print('correct', correct)\n",
    "    return loss.item(), acc\n",
    "\n",
    "# Testing\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index) if isinstance(model, GCN) else model(data.x)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = (pred[data.test_mask] == data.y[data.test_mask]).sum().item()\n",
    "        total = data.test_mask.sum().item()\n",
    "        acc = correct / total\n",
    "    return acc\n",
    "\n",
    "# Train and evaluate the model\n",
    "def train_and_evaluate(model, data, epochs=100, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, data, optimizer, criterion)\n",
    "        val_loss, val_acc = validate(model, data, criterion)\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict()\n",
    "            # record the best epoch information for model hypertuning\n",
    "            best_epoch_info = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc\n",
    "            }\n",
    "    # Load the best model and evaluate on the test set\n",
    "    model.load_state_dict(best_model)\n",
    "    test_acc = test(model, data)\n",
    "    # output the best epoch information for model hypertuning\n",
    "    print(f\"Best Epoch: {best_epoch_info['epoch']}, \"\n",
    "          f\"Train Loss: {best_epoch_info['train_loss']:.4f}, \"\n",
    "          f\"Val Loss: {best_epoch_info['val_loss']:.4f}, \"\n",
    "          f\"Val Acc: {best_epoch_info['val_acc']:.4f}\")\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    return test_acc\n",
    "\n",
    "# initialize the model\n",
    "input_dim = data.num_features\n",
    "\n",
    "output_dim = torch.unique(data.y).size(0)\n",
    "\n",
    "# train and evaluate 2-layer GCN\n",
    "print(\"Training 2-layer GCN...\")\n",
    "# after hyperparameter tuning, the best hidden_dim and learning rate are 64 and 0.005 respectively\n",
    "hidden_dim = 64\n",
    "gcn = GCN(input_dim, hidden_dim, output_dim)\n",
    "gcn_test_acc = train_and_evaluate(gcn, data, lr=0.005)\n",
    "\n",
    "# train and evaluate 2-layer MLP\n",
    "print(\"Training 2-layer MLP...\")\n",
    "# after hyperparameter tuning, the best hidden_dim and learning rate are 32 and 0.005 respectively\n",
    "hidden_dim = 32\n",
    "mlp = MLP(input_dim, hidden_dim, output_dim)\n",
    "mlp_test_acc = train_and_evaluate(mlp, data, lr=0.005)\n",
    "\n",
    "# Compare the results\n",
    "print(f\"2-layer GCN Test Accuracy: {gcn_test_acc:.4f}\")\n",
    "print(f\"2-layer MLP Test Accuracy: {mlp_test_acc:.4f}\")\n",
    "\n",
    "if gcn_test_acc > mlp_test_acc:\n",
    "    print(\"GCN outperforms MLP because it utilizes graph structure information by aggregating neighbor nodes, capturing local relationships. In contrast, MLP only relies on node features, ignoring the graph's connectivity, which limits its ability to model interactions between nodes\")\n",
    "else:\n",
    "    print(\"MLP performs better than GCN, this may due to the graph architecture is not helpful for the current task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2-layer GCN...\n",
      "Epoch 1, Train Loss: 1.7934, Val Loss: 1.7161, Val Acc: 0.5160\n",
      "Epoch 2, Train Loss: 1.5660, Val Loss: 1.6204, Val Acc: 0.6080\n",
      "Epoch 3, Train Loss: 1.3657, Val Loss: 1.5102, Val Acc: 0.6420\n",
      "Epoch 4, Train Loss: 1.0990, Val Loss: 1.3999, Val Acc: 0.6560\n",
      "Epoch 5, Train Loss: 0.8452, Val Loss: 1.2960, Val Acc: 0.7000\n",
      "Epoch 6, Train Loss: 0.6777, Val Loss: 1.2022, Val Acc: 0.7080\n",
      "Epoch 7, Train Loss: 0.5318, Val Loss: 1.1252, Val Acc: 0.7080\n",
      "Epoch 8, Train Loss: 0.3818, Val Loss: 1.0677, Val Acc: 0.7100\n",
      "Epoch 9, Train Loss: 0.2747, Val Loss: 1.0275, Val Acc: 0.7100\n",
      "Epoch 10, Train Loss: 0.2191, Val Loss: 1.0007, Val Acc: 0.7040\n",
      "Epoch 11, Train Loss: 0.1792, Val Loss: 0.9845, Val Acc: 0.6900\n",
      "Epoch 12, Train Loss: 0.1405, Val Loss: 0.9801, Val Acc: 0.6760\n",
      "Epoch 13, Train Loss: 0.1143, Val Loss: 0.9815, Val Acc: 0.6740\n",
      "Epoch 14, Train Loss: 0.0821, Val Loss: 0.9907, Val Acc: 0.6660\n",
      "Epoch 15, Train Loss: 0.0741, Val Loss: 1.0056, Val Acc: 0.6640\n",
      "Epoch 16, Train Loss: 0.0595, Val Loss: 1.0199, Val Acc: 0.6600\n",
      "Epoch 17, Train Loss: 0.0598, Val Loss: 1.0403, Val Acc: 0.6540\n",
      "Epoch 18, Train Loss: 0.0330, Val Loss: 1.0607, Val Acc: 0.6560\n",
      "Epoch 19, Train Loss: 0.0320, Val Loss: 1.0793, Val Acc: 0.6580\n",
      "Epoch 20, Train Loss: 0.0327, Val Loss: 1.0946, Val Acc: 0.6560\n",
      "Epoch 21, Train Loss: 0.0241, Val Loss: 1.1107, Val Acc: 0.6480\n",
      "Epoch 22, Train Loss: 0.0289, Val Loss: 1.1215, Val Acc: 0.6460\n",
      "Epoch 23, Train Loss: 0.0219, Val Loss: 1.1293, Val Acc: 0.6440\n",
      "Epoch 24, Train Loss: 0.0151, Val Loss: 1.1376, Val Acc: 0.6460\n",
      "Epoch 25, Train Loss: 0.0174, Val Loss: 1.1470, Val Acc: 0.6480\n",
      "Epoch 26, Train Loss: 0.0126, Val Loss: 1.1576, Val Acc: 0.6460\n",
      "Epoch 27, Train Loss: 0.0295, Val Loss: 1.1733, Val Acc: 0.6460\n",
      "Epoch 28, Train Loss: 0.0106, Val Loss: 1.1891, Val Acc: 0.6460\n",
      "Epoch 29, Train Loss: 0.0083, Val Loss: 1.2057, Val Acc: 0.6460\n",
      "Epoch 30, Train Loss: 0.0120, Val Loss: 1.2198, Val Acc: 0.6440\n",
      "Epoch 31, Train Loss: 0.0098, Val Loss: 1.2343, Val Acc: 0.6400\n",
      "Epoch 32, Train Loss: 0.0119, Val Loss: 1.2461, Val Acc: 0.6380\n",
      "Epoch 33, Train Loss: 0.0069, Val Loss: 1.2573, Val Acc: 0.6400\n",
      "Epoch 34, Train Loss: 0.0057, Val Loss: 1.2688, Val Acc: 0.6420\n",
      "Epoch 35, Train Loss: 0.0067, Val Loss: 1.2813, Val Acc: 0.6400\n",
      "Epoch 36, Train Loss: 0.0066, Val Loss: 1.2917, Val Acc: 0.6420\n",
      "Epoch 37, Train Loss: 0.0076, Val Loss: 1.2999, Val Acc: 0.6420\n",
      "Epoch 38, Train Loss: 0.0045, Val Loss: 1.3066, Val Acc: 0.6400\n",
      "Epoch 39, Train Loss: 0.0070, Val Loss: 1.3118, Val Acc: 0.6380\n",
      "Epoch 40, Train Loss: 0.0046, Val Loss: 1.3167, Val Acc: 0.6380\n",
      "Epoch 41, Train Loss: 0.0036, Val Loss: 1.3208, Val Acc: 0.6360\n",
      "Epoch 42, Train Loss: 0.0028, Val Loss: 1.3249, Val Acc: 0.6360\n",
      "Epoch 43, Train Loss: 0.0039, Val Loss: 1.3282, Val Acc: 0.6400\n",
      "Epoch 44, Train Loss: 0.0036, Val Loss: 1.3304, Val Acc: 0.6400\n",
      "Epoch 45, Train Loss: 0.0047, Val Loss: 1.3334, Val Acc: 0.6400\n",
      "Epoch 46, Train Loss: 0.0077, Val Loss: 1.3356, Val Acc: 0.6380\n",
      "Epoch 47, Train Loss: 0.0050, Val Loss: 1.3395, Val Acc: 0.6360\n",
      "Epoch 48, Train Loss: 0.0024, Val Loss: 1.3431, Val Acc: 0.6360\n",
      "Epoch 49, Train Loss: 0.0037, Val Loss: 1.3457, Val Acc: 0.6360\n",
      "Epoch 50, Train Loss: 0.0030, Val Loss: 1.3480, Val Acc: 0.6360\n",
      "Epoch 51, Train Loss: 0.0032, Val Loss: 1.3490, Val Acc: 0.6360\n",
      "Epoch 52, Train Loss: 0.0020, Val Loss: 1.3502, Val Acc: 0.6360\n",
      "Epoch 53, Train Loss: 0.0021, Val Loss: 1.3514, Val Acc: 0.6360\n",
      "Epoch 54, Train Loss: 0.0026, Val Loss: 1.3530, Val Acc: 0.6360\n",
      "Epoch 55, Train Loss: 0.0030, Val Loss: 1.3553, Val Acc: 0.6360\n",
      "Epoch 56, Train Loss: 0.0053, Val Loss: 1.3586, Val Acc: 0.6380\n",
      "Epoch 57, Train Loss: 0.0018, Val Loss: 1.3617, Val Acc: 0.6380\n",
      "Epoch 58, Train Loss: 0.0031, Val Loss: 1.3650, Val Acc: 0.6380\n",
      "Epoch 59, Train Loss: 0.0026, Val Loss: 1.3687, Val Acc: 0.6380\n",
      "Epoch 60, Train Loss: 0.0043, Val Loss: 1.3711, Val Acc: 0.6380\n",
      "Epoch 61, Train Loss: 0.0039, Val Loss: 1.3722, Val Acc: 0.6380\n",
      "Epoch 62, Train Loss: 0.0017, Val Loss: 1.3735, Val Acc: 0.6400\n",
      "Epoch 63, Train Loss: 0.0033, Val Loss: 1.3748, Val Acc: 0.6360\n",
      "Epoch 64, Train Loss: 0.0016, Val Loss: 1.3764, Val Acc: 0.6360\n",
      "Epoch 65, Train Loss: 0.0052, Val Loss: 1.3772, Val Acc: 0.6400\n",
      "Epoch 66, Train Loss: 0.0015, Val Loss: 1.3785, Val Acc: 0.6400\n",
      "Epoch 67, Train Loss: 0.0022, Val Loss: 1.3806, Val Acc: 0.6420\n",
      "Epoch 68, Train Loss: 0.0038, Val Loss: 1.3819, Val Acc: 0.6420\n",
      "Epoch 69, Train Loss: 0.0023, Val Loss: 1.3832, Val Acc: 0.6460\n",
      "Epoch 70, Train Loss: 0.0016, Val Loss: 1.3845, Val Acc: 0.6480\n",
      "Epoch 71, Train Loss: 0.0021, Val Loss: 1.3862, Val Acc: 0.6500\n",
      "Epoch 72, Train Loss: 0.0017, Val Loss: 1.3880, Val Acc: 0.6500\n",
      "Epoch 73, Train Loss: 0.0015, Val Loss: 1.3894, Val Acc: 0.6500\n",
      "Epoch 74, Train Loss: 0.0022, Val Loss: 1.3909, Val Acc: 0.6500\n",
      "Epoch 75, Train Loss: 0.0134, Val Loss: 1.3911, Val Acc: 0.6500\n",
      "Epoch 76, Train Loss: 0.0020, Val Loss: 1.3913, Val Acc: 0.6500\n",
      "Epoch 77, Train Loss: 0.0021, Val Loss: 1.3921, Val Acc: 0.6500\n",
      "Epoch 78, Train Loss: 0.0025, Val Loss: 1.3936, Val Acc: 0.6460\n",
      "Epoch 79, Train Loss: 0.0017, Val Loss: 1.3955, Val Acc: 0.6420\n",
      "Epoch 80, Train Loss: 0.0019, Val Loss: 1.3974, Val Acc: 0.6420\n",
      "Epoch 81, Train Loss: 0.0025, Val Loss: 1.4008, Val Acc: 0.6440\n",
      "Epoch 82, Train Loss: 0.0011, Val Loss: 1.4041, Val Acc: 0.6440\n",
      "Epoch 83, Train Loss: 0.0011, Val Loss: 1.4073, Val Acc: 0.6460\n",
      "Epoch 84, Train Loss: 0.0014, Val Loss: 1.4104, Val Acc: 0.6400\n",
      "Epoch 85, Train Loss: 0.0013, Val Loss: 1.4136, Val Acc: 0.6400\n",
      "Epoch 86, Train Loss: 0.0015, Val Loss: 1.4166, Val Acc: 0.6420\n",
      "Epoch 87, Train Loss: 0.0013, Val Loss: 1.4198, Val Acc: 0.6420\n",
      "Epoch 88, Train Loss: 0.0013, Val Loss: 1.4227, Val Acc: 0.6420\n",
      "Epoch 89, Train Loss: 0.0010, Val Loss: 1.4256, Val Acc: 0.6420\n",
      "Epoch 90, Train Loss: 0.0020, Val Loss: 1.4278, Val Acc: 0.6380\n",
      "Epoch 91, Train Loss: 0.0012, Val Loss: 1.4302, Val Acc: 0.6360\n",
      "Epoch 92, Train Loss: 0.0013, Val Loss: 1.4319, Val Acc: 0.6340\n",
      "Epoch 93, Train Loss: 0.0010, Val Loss: 1.4336, Val Acc: 0.6340\n",
      "Epoch 94, Train Loss: 0.0024, Val Loss: 1.4350, Val Acc: 0.6360\n",
      "Epoch 95, Train Loss: 0.0012, Val Loss: 1.4363, Val Acc: 0.6360\n",
      "Epoch 96, Train Loss: 0.0011, Val Loss: 1.4372, Val Acc: 0.6360\n",
      "Epoch 97, Train Loss: 0.0011, Val Loss: 1.4380, Val Acc: 0.6360\n",
      "Epoch 98, Train Loss: 0.0015, Val Loss: 1.4383, Val Acc: 0.6380\n",
      "Epoch 99, Train Loss: 0.0010, Val Loss: 1.4385, Val Acc: 0.6380\n",
      "Epoch 100, Train Loss: 0.0015, Val Loss: 1.4390, Val Acc: 0.6400\n",
      "Best Epoch: 8, Train Loss: 0.3818, Val Loss: 1.0677, Val Acc: 0.7100\n",
      "2-layer GCN Test Accuracy: 0.6500\n",
      "Training 4-layer GCN...\n",
      "Epoch 1, Train Loss: 1.7854, Val Loss: 1.7691, Val Acc: 0.2200\n",
      "Epoch 2, Train Loss: 1.7406, Val Loss: 1.7294, Val Acc: 0.2100\n",
      "Epoch 3, Train Loss: 1.6680, Val Loss: 1.6782, Val Acc: 0.2340\n",
      "Epoch 4, Train Loss: 1.5718, Val Loss: 1.6183, Val Acc: 0.2700\n",
      "Epoch 5, Train Loss: 1.4438, Val Loss: 1.5341, Val Acc: 0.3560\n",
      "Epoch 6, Train Loss: 1.3268, Val Loss: 1.4282, Val Acc: 0.4700\n",
      "Epoch 7, Train Loss: 1.1523, Val Loss: 1.3241, Val Acc: 0.5080\n",
      "Epoch 8, Train Loss: 1.0140, Val Loss: 1.2366, Val Acc: 0.5300\n",
      "Epoch 9, Train Loss: 0.8560, Val Loss: 1.1573, Val Acc: 0.6280\n",
      "Epoch 10, Train Loss: 0.7406, Val Loss: 1.0802, Val Acc: 0.6520\n",
      "Epoch 11, Train Loss: 0.6214, Val Loss: 1.0290, Val Acc: 0.6520\n",
      "Epoch 12, Train Loss: 0.4455, Val Loss: 1.0374, Val Acc: 0.6440\n",
      "Epoch 13, Train Loss: 0.4064, Val Loss: 1.1011, Val Acc: 0.6320\n",
      "Epoch 14, Train Loss: 0.3138, Val Loss: 1.2253, Val Acc: 0.6280\n",
      "Epoch 15, Train Loss: 0.2977, Val Loss: 1.3167, Val Acc: 0.6320\n",
      "Epoch 16, Train Loss: 0.1932, Val Loss: 1.4095, Val Acc: 0.6280\n",
      "Epoch 17, Train Loss: 0.1436, Val Loss: 1.5033, Val Acc: 0.6320\n",
      "Epoch 18, Train Loss: 0.1507, Val Loss: 1.6153, Val Acc: 0.6360\n",
      "Epoch 19, Train Loss: 0.1511, Val Loss: 1.6731, Val Acc: 0.6420\n",
      "Epoch 20, Train Loss: 0.1247, Val Loss: 1.7512, Val Acc: 0.6460\n",
      "Epoch 21, Train Loss: 0.1465, Val Loss: 1.8655, Val Acc: 0.6440\n",
      "Epoch 22, Train Loss: 0.1020, Val Loss: 2.0360, Val Acc: 0.6340\n",
      "Epoch 23, Train Loss: 0.2127, Val Loss: 2.2467, Val Acc: 0.6220\n",
      "Epoch 24, Train Loss: 0.1304, Val Loss: 2.3323, Val Acc: 0.6200\n",
      "Epoch 25, Train Loss: 0.0939, Val Loss: 2.3554, Val Acc: 0.6320\n",
      "Epoch 26, Train Loss: 0.0781, Val Loss: 2.4125, Val Acc: 0.6280\n",
      "Epoch 27, Train Loss: 0.0797, Val Loss: 2.4683, Val Acc: 0.6280\n",
      "Epoch 28, Train Loss: 0.0754, Val Loss: 2.4924, Val Acc: 0.6260\n",
      "Epoch 29, Train Loss: 0.0438, Val Loss: 2.4970, Val Acc: 0.6220\n",
      "Epoch 30, Train Loss: 0.1799, Val Loss: 2.4904, Val Acc: 0.6200\n",
      "Epoch 31, Train Loss: 0.1062, Val Loss: 2.5270, Val Acc: 0.6180\n",
      "Epoch 32, Train Loss: 0.0611, Val Loss: 2.5767, Val Acc: 0.6120\n",
      "Epoch 33, Train Loss: 0.0625, Val Loss: 2.6600, Val Acc: 0.6140\n",
      "Epoch 34, Train Loss: 0.0742, Val Loss: 2.7205, Val Acc: 0.6220\n",
      "Epoch 35, Train Loss: 0.0867, Val Loss: 2.8024, Val Acc: 0.6160\n",
      "Epoch 36, Train Loss: 0.0259, Val Loss: 2.8699, Val Acc: 0.6000\n",
      "Epoch 37, Train Loss: 0.0729, Val Loss: 2.8655, Val Acc: 0.6020\n",
      "Epoch 38, Train Loss: 0.0563, Val Loss: 2.8157, Val Acc: 0.6160\n",
      "Epoch 39, Train Loss: 0.0316, Val Loss: 2.7828, Val Acc: 0.6200\n",
      "Epoch 40, Train Loss: 0.0415, Val Loss: 2.7550, Val Acc: 0.6300\n",
      "Epoch 41, Train Loss: 0.0511, Val Loss: 2.7233, Val Acc: 0.6160\n",
      "Epoch 42, Train Loss: 0.0548, Val Loss: 2.7182, Val Acc: 0.6220\n",
      "Epoch 43, Train Loss: 0.0443, Val Loss: 2.7216, Val Acc: 0.6200\n",
      "Epoch 44, Train Loss: 0.0394, Val Loss: 2.7518, Val Acc: 0.6180\n",
      "Epoch 45, Train Loss: 0.0246, Val Loss: 2.8073, Val Acc: 0.6100\n",
      "Epoch 46, Train Loss: 0.0435, Val Loss: 2.8934, Val Acc: 0.6040\n",
      "Epoch 47, Train Loss: 0.0268, Val Loss: 2.9910, Val Acc: 0.6020\n",
      "Epoch 48, Train Loss: 0.0568, Val Loss: 3.0361, Val Acc: 0.6020\n",
      "Epoch 49, Train Loss: 0.0408, Val Loss: 3.0500, Val Acc: 0.5960\n",
      "Epoch 50, Train Loss: 0.0253, Val Loss: 3.0818, Val Acc: 0.5880\n",
      "Epoch 51, Train Loss: 0.0324, Val Loss: 3.0630, Val Acc: 0.5980\n",
      "Epoch 52, Train Loss: 0.0452, Val Loss: 3.0486, Val Acc: 0.6000\n",
      "Epoch 53, Train Loss: 0.0139, Val Loss: 3.0413, Val Acc: 0.6020\n",
      "Epoch 54, Train Loss: 0.0577, Val Loss: 2.9602, Val Acc: 0.6100\n",
      "Epoch 55, Train Loss: 0.0117, Val Loss: 2.9174, Val Acc: 0.6140\n",
      "Epoch 56, Train Loss: 0.0102, Val Loss: 2.9024, Val Acc: 0.6140\n",
      "Epoch 57, Train Loss: 0.0333, Val Loss: 2.8929, Val Acc: 0.6140\n",
      "Epoch 58, Train Loss: 0.0161, Val Loss: 2.8942, Val Acc: 0.6220\n",
      "Epoch 59, Train Loss: 0.0219, Val Loss: 2.9040, Val Acc: 0.6240\n",
      "Epoch 60, Train Loss: 0.0291, Val Loss: 2.9299, Val Acc: 0.6240\n",
      "Epoch 61, Train Loss: 0.0596, Val Loss: 2.9624, Val Acc: 0.6240\n",
      "Epoch 62, Train Loss: 0.0349, Val Loss: 3.0089, Val Acc: 0.6220\n",
      "Epoch 63, Train Loss: 0.0242, Val Loss: 3.0713, Val Acc: 0.6200\n",
      "Epoch 64, Train Loss: 0.0434, Val Loss: 3.1360, Val Acc: 0.6200\n",
      "Epoch 65, Train Loss: 0.0293, Val Loss: 3.1678, Val Acc: 0.6180\n",
      "Epoch 66, Train Loss: 0.0102, Val Loss: 3.1926, Val Acc: 0.6160\n",
      "Epoch 67, Train Loss: 0.0160, Val Loss: 3.1890, Val Acc: 0.6200\n",
      "Epoch 68, Train Loss: 0.0120, Val Loss: 3.1821, Val Acc: 0.6220\n",
      "Epoch 69, Train Loss: 0.0133, Val Loss: 3.1838, Val Acc: 0.6240\n",
      "Epoch 70, Train Loss: 0.0133, Val Loss: 3.1875, Val Acc: 0.6180\n",
      "Epoch 71, Train Loss: 0.0193, Val Loss: 3.2131, Val Acc: 0.6160\n",
      "Epoch 72, Train Loss: 0.0386, Val Loss: 3.2448, Val Acc: 0.6140\n",
      "Epoch 73, Train Loss: 0.0108, Val Loss: 3.2839, Val Acc: 0.6100\n",
      "Epoch 74, Train Loss: 0.0227, Val Loss: 3.3178, Val Acc: 0.6180\n",
      "Epoch 75, Train Loss: 0.0198, Val Loss: 3.3364, Val Acc: 0.6180\n",
      "Epoch 76, Train Loss: 0.0136, Val Loss: 3.3581, Val Acc: 0.6180\n",
      "Epoch 77, Train Loss: 0.0216, Val Loss: 3.3758, Val Acc: 0.6220\n",
      "Epoch 78, Train Loss: 0.0079, Val Loss: 3.3981, Val Acc: 0.6240\n",
      "Epoch 79, Train Loss: 0.0158, Val Loss: 3.4204, Val Acc: 0.6240\n",
      "Epoch 80, Train Loss: 0.0104, Val Loss: 3.4376, Val Acc: 0.6240\n",
      "Epoch 81, Train Loss: 0.0126, Val Loss: 3.4442, Val Acc: 0.6240\n",
      "Epoch 82, Train Loss: 0.0058, Val Loss: 3.4537, Val Acc: 0.6260\n",
      "Epoch 83, Train Loss: 0.0259, Val Loss: 3.4658, Val Acc: 0.6280\n",
      "Epoch 84, Train Loss: 0.0111, Val Loss: 3.4773, Val Acc: 0.6260\n",
      "Epoch 85, Train Loss: 0.0194, Val Loss: 3.4921, Val Acc: 0.6260\n",
      "Epoch 86, Train Loss: 0.0040, Val Loss: 3.5133, Val Acc: 0.6240\n",
      "Epoch 87, Train Loss: 0.0160, Val Loss: 3.5484, Val Acc: 0.6260\n",
      "Epoch 88, Train Loss: 0.0103, Val Loss: 3.5833, Val Acc: 0.6200\n",
      "Epoch 89, Train Loss: 0.0387, Val Loss: 3.6365, Val Acc: 0.6160\n",
      "Epoch 90, Train Loss: 0.0076, Val Loss: 3.6941, Val Acc: 0.6140\n",
      "Epoch 91, Train Loss: 0.0526, Val Loss: 3.7646, Val Acc: 0.6120\n",
      "Epoch 92, Train Loss: 0.0173, Val Loss: 3.8000, Val Acc: 0.6100\n",
      "Epoch 93, Train Loss: 0.0033, Val Loss: 3.8339, Val Acc: 0.6120\n",
      "Epoch 94, Train Loss: 0.0117, Val Loss: 3.8568, Val Acc: 0.6120\n",
      "Epoch 95, Train Loss: 0.0386, Val Loss: 3.8510, Val Acc: 0.6140\n",
      "Epoch 96, Train Loss: 0.0658, Val Loss: 3.7597, Val Acc: 0.6120\n",
      "Epoch 97, Train Loss: 0.0118, Val Loss: 3.7025, Val Acc: 0.6240\n",
      "Epoch 98, Train Loss: 0.0048, Val Loss: 3.6742, Val Acc: 0.6260\n",
      "Epoch 99, Train Loss: 0.0129, Val Loss: 3.6662, Val Acc: 0.6240\n",
      "Epoch 100, Train Loss: 0.0239, Val Loss: 3.6742, Val Acc: 0.6240\n",
      "Best Epoch: 10, Train Loss: 0.7406, Val Loss: 1.0802, Val Acc: 0.6520\n",
      "4-layer GCN Test Accuracy: 0.6220\n",
      "Training 6-layer GCN...\n",
      "Epoch 1, Train Loss: 1.7914, Val Loss: 1.7940, Val Acc: 0.0580\n",
      "Epoch 2, Train Loss: 1.7698, Val Loss: 1.7708, Val Acc: 0.0820\n",
      "Epoch 3, Train Loss: 1.7563, Val Loss: 1.6847, Val Acc: 0.3520\n",
      "Epoch 4, Train Loss: 1.5858, Val Loss: 1.5456, Val Acc: 0.3700\n",
      "Epoch 5, Train Loss: 1.4284, Val Loss: 1.3911, Val Acc: 0.3920\n",
      "Epoch 6, Train Loss: 1.2620, Val Loss: 1.2164, Val Acc: 0.5440\n",
      "Epoch 7, Train Loss: 1.0098, Val Loss: 1.1961, Val Acc: 0.5360\n",
      "Epoch 8, Train Loss: 0.9344, Val Loss: 1.3686, Val Acc: 0.6060\n",
      "Epoch 9, Train Loss: 0.7733, Val Loss: 1.4016, Val Acc: 0.6080\n",
      "Epoch 10, Train Loss: 0.6589, Val Loss: 1.3668, Val Acc: 0.6360\n",
      "Epoch 11, Train Loss: 0.5283, Val Loss: 1.4840, Val Acc: 0.6420\n",
      "Epoch 12, Train Loss: 0.4930, Val Loss: 1.7597, Val Acc: 0.6240\n",
      "Epoch 13, Train Loss: 0.4366, Val Loss: 1.8815, Val Acc: 0.6400\n",
      "Epoch 14, Train Loss: 0.4170, Val Loss: 2.1919, Val Acc: 0.5940\n",
      "Epoch 15, Train Loss: 0.4273, Val Loss: 2.1094, Val Acc: 0.6380\n",
      "Epoch 16, Train Loss: 0.3601, Val Loss: 2.1808, Val Acc: 0.6340\n",
      "Epoch 17, Train Loss: 0.3681, Val Loss: 2.1412, Val Acc: 0.6420\n",
      "Epoch 18, Train Loss: 0.2941, Val Loss: 2.1597, Val Acc: 0.6440\n",
      "Epoch 19, Train Loss: 0.3424, Val Loss: 2.2530, Val Acc: 0.6280\n",
      "Epoch 20, Train Loss: 0.2174, Val Loss: 2.3983, Val Acc: 0.6280\n",
      "Epoch 21, Train Loss: 0.2391, Val Loss: 2.4217, Val Acc: 0.6260\n",
      "Epoch 22, Train Loss: 0.2462, Val Loss: 2.3347, Val Acc: 0.6300\n",
      "Epoch 23, Train Loss: 0.2533, Val Loss: 2.2568, Val Acc: 0.6380\n",
      "Epoch 24, Train Loss: 0.2092, Val Loss: 2.2576, Val Acc: 0.6380\n",
      "Epoch 25, Train Loss: 0.1483, Val Loss: 2.3130, Val Acc: 0.6460\n",
      "Epoch 26, Train Loss: 0.1963, Val Loss: 2.3961, Val Acc: 0.6380\n",
      "Epoch 27, Train Loss: 0.1571, Val Loss: 2.5306, Val Acc: 0.6260\n",
      "Epoch 28, Train Loss: 0.1795, Val Loss: 2.7165, Val Acc: 0.6140\n",
      "Epoch 29, Train Loss: 0.1026, Val Loss: 2.8201, Val Acc: 0.6080\n",
      "Epoch 30, Train Loss: 0.1930, Val Loss: 2.8004, Val Acc: 0.6120\n",
      "Epoch 31, Train Loss: 0.1712, Val Loss: 2.7365, Val Acc: 0.6200\n",
      "Epoch 32, Train Loss: 0.1430, Val Loss: 2.7384, Val Acc: 0.6160\n",
      "Epoch 33, Train Loss: 0.0760, Val Loss: 2.7989, Val Acc: 0.6260\n",
      "Epoch 34, Train Loss: 0.0858, Val Loss: 2.9097, Val Acc: 0.6260\n",
      "Epoch 35, Train Loss: 0.0844, Val Loss: 3.0729, Val Acc: 0.6080\n",
      "Epoch 36, Train Loss: 0.1327, Val Loss: 3.2566, Val Acc: 0.6040\n",
      "Epoch 37, Train Loss: 0.1101, Val Loss: 3.2805, Val Acc: 0.6180\n",
      "Epoch 38, Train Loss: 0.1256, Val Loss: 3.2529, Val Acc: 0.6300\n",
      "Epoch 39, Train Loss: 0.0597, Val Loss: 3.2318, Val Acc: 0.6240\n",
      "Epoch 40, Train Loss: 0.0611, Val Loss: 3.2587, Val Acc: 0.6280\n",
      "Epoch 41, Train Loss: 0.2612, Val Loss: 3.2293, Val Acc: 0.6380\n",
      "Epoch 42, Train Loss: 0.1009, Val Loss: 3.2782, Val Acc: 0.6400\n",
      "Epoch 43, Train Loss: 0.1117, Val Loss: 3.3355, Val Acc: 0.6400\n",
      "Epoch 44, Train Loss: 0.0642, Val Loss: 3.3862, Val Acc: 0.6260\n",
      "Epoch 45, Train Loss: 0.1752, Val Loss: 3.5086, Val Acc: 0.6200\n",
      "Epoch 46, Train Loss: 0.1390, Val Loss: 3.6755, Val Acc: 0.6140\n",
      "Epoch 47, Train Loss: 0.0985, Val Loss: 3.8010, Val Acc: 0.6080\n",
      "Epoch 48, Train Loss: 0.1080, Val Loss: 3.8239, Val Acc: 0.5960\n",
      "Epoch 49, Train Loss: 0.0744, Val Loss: 3.7120, Val Acc: 0.5920\n",
      "Epoch 50, Train Loss: 0.1243, Val Loss: 3.5688, Val Acc: 0.5940\n",
      "Epoch 51, Train Loss: 0.0931, Val Loss: 3.5633, Val Acc: 0.5900\n",
      "Epoch 52, Train Loss: 0.1150, Val Loss: 3.6291, Val Acc: 0.5900\n",
      "Epoch 53, Train Loss: 0.0770, Val Loss: 3.8852, Val Acc: 0.5940\n",
      "Epoch 54, Train Loss: 0.0840, Val Loss: 4.1510, Val Acc: 0.5800\n",
      "Epoch 55, Train Loss: 0.1078, Val Loss: 4.3579, Val Acc: 0.5800\n",
      "Epoch 56, Train Loss: 1.0746, Val Loss: 3.9209, Val Acc: 0.6000\n",
      "Epoch 57, Train Loss: 0.0748, Val Loss: 3.6398, Val Acc: 0.6040\n",
      "Epoch 58, Train Loss: 0.0881, Val Loss: 3.5466, Val Acc: 0.6000\n",
      "Epoch 59, Train Loss: 0.0678, Val Loss: 3.5459, Val Acc: 0.5880\n",
      "Epoch 60, Train Loss: 0.0755, Val Loss: 3.5616, Val Acc: 0.5740\n",
      "Epoch 61, Train Loss: 0.0957, Val Loss: 3.5558, Val Acc: 0.5780\n",
      "Epoch 62, Train Loss: 0.1335, Val Loss: 3.5484, Val Acc: 0.5680\n",
      "Epoch 63, Train Loss: 0.0717, Val Loss: 3.5270, Val Acc: 0.5660\n",
      "Epoch 64, Train Loss: 0.0499, Val Loss: 3.5304, Val Acc: 0.5640\n",
      "Epoch 65, Train Loss: 0.0369, Val Loss: 3.5490, Val Acc: 0.5660\n",
      "Epoch 66, Train Loss: 0.0824, Val Loss: 3.5954, Val Acc: 0.5640\n",
      "Epoch 67, Train Loss: 0.0539, Val Loss: 3.6401, Val Acc: 0.5760\n",
      "Epoch 68, Train Loss: 0.0567, Val Loss: 3.6685, Val Acc: 0.5780\n",
      "Epoch 69, Train Loss: 0.0686, Val Loss: 3.6830, Val Acc: 0.5820\n",
      "Epoch 70, Train Loss: 0.0748, Val Loss: 3.6767, Val Acc: 0.5880\n",
      "Epoch 71, Train Loss: 0.1097, Val Loss: 3.6972, Val Acc: 0.6020\n",
      "Epoch 72, Train Loss: 0.0422, Val Loss: 3.7451, Val Acc: 0.6080\n",
      "Epoch 73, Train Loss: 0.0426, Val Loss: 3.8307, Val Acc: 0.6120\n",
      "Epoch 74, Train Loss: 0.0627, Val Loss: 3.9172, Val Acc: 0.6120\n",
      "Epoch 75, Train Loss: 0.0450, Val Loss: 4.0464, Val Acc: 0.6100\n",
      "Epoch 76, Train Loss: 0.0702, Val Loss: 4.1726, Val Acc: 0.6100\n",
      "Epoch 77, Train Loss: 0.0355, Val Loss: 4.3022, Val Acc: 0.6100\n",
      "Epoch 78, Train Loss: 0.0360, Val Loss: 4.4224, Val Acc: 0.6080\n",
      "Epoch 79, Train Loss: 0.0562, Val Loss: 4.4894, Val Acc: 0.6140\n",
      "Epoch 80, Train Loss: 0.0339, Val Loss: 4.5510, Val Acc: 0.6140\n",
      "Epoch 81, Train Loss: 0.0776, Val Loss: 4.5635, Val Acc: 0.6120\n",
      "Epoch 82, Train Loss: 0.0251, Val Loss: 4.6185, Val Acc: 0.6200\n",
      "Epoch 83, Train Loss: 0.0307, Val Loss: 4.7362, Val Acc: 0.6160\n",
      "Epoch 84, Train Loss: 0.0267, Val Loss: 4.8601, Val Acc: 0.6100\n",
      "Epoch 85, Train Loss: 0.0203, Val Loss: 4.9971, Val Acc: 0.6040\n",
      "Epoch 86, Train Loss: 0.0630, Val Loss: 5.1367, Val Acc: 0.5980\n",
      "Epoch 87, Train Loss: 0.0286, Val Loss: 5.3012, Val Acc: 0.5980\n",
      "Epoch 88, Train Loss: 0.0792, Val Loss: 5.4638, Val Acc: 0.5940\n",
      "Epoch 89, Train Loss: 0.0996, Val Loss: 5.5196, Val Acc: 0.5900\n",
      "Epoch 90, Train Loss: 0.0160, Val Loss: 5.6087, Val Acc: 0.5960\n",
      "Epoch 91, Train Loss: 0.0366, Val Loss: 5.6849, Val Acc: 0.5880\n",
      "Epoch 92, Train Loss: 0.1003, Val Loss: 5.6340, Val Acc: 0.5900\n",
      "Epoch 93, Train Loss: 0.1351, Val Loss: 5.5488, Val Acc: 0.5940\n",
      "Epoch 94, Train Loss: 0.0216, Val Loss: 5.5289, Val Acc: 0.5940\n",
      "Epoch 95, Train Loss: 0.0405, Val Loss: 5.5953, Val Acc: 0.5900\n",
      "Epoch 96, Train Loss: 0.1948, Val Loss: 5.6643, Val Acc: 0.5900\n",
      "Epoch 97, Train Loss: 0.0227, Val Loss: 5.7968, Val Acc: 0.5900\n",
      "Epoch 98, Train Loss: 0.0731, Val Loss: 5.8235, Val Acc: 0.5820\n",
      "Epoch 99, Train Loss: 0.0371, Val Loss: 5.8090, Val Acc: 0.5780\n",
      "Epoch 100, Train Loss: 0.0164, Val Loss: 5.7865, Val Acc: 0.5780\n",
      "Best Epoch: 25, Train Loss: 0.1483, Val Loss: 2.3130, Val Acc: 0.6460\n",
      "6-layer GCN Test Accuracy: 0.5550\n",
      "2-layer GCN Test Accuracy: 0.6500\n",
      "4-layer GCN Test Accuracy: 0.6220\n",
      "6-layer GCN Test Accuracy: 0.5550\n",
      "2 layer GCN performs the best. This is due to the fact that as layers increase, the model will become over-smoothing, where node representations are indistinguishable. Additionally, a 2-layer GCN effectively captures local neighborhood information without excessive complexity, making it more robust and efficient for the given task.\n"
     ]
    }
   ],
   "source": [
    "# define GCN with multiple layers\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(input_dim, hidden_dim))\n",
    "        for i in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "        self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# train and evaluate GCN with multiple layers\n",
    "def train_and_evaluate_gcn(data, num_layers, epochs=100, lr=0.01):\n",
    "    # print('hidden dim:', hidden_dim)\n",
    "    model = GCN(input_dim, hidden_dim, output_dim, num_layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, data, optimizer, criterion)\n",
    "        val_loss, val_acc = validate(model, data, criterion)\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict()\n",
    "            # record the best epoch information for model hypertuning\n",
    "            best_epoch_info = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc\n",
    "            }\n",
    "\n",
    "    # load the best model and evaluate on the test set\n",
    "    model.load_state_dict(best_model)\n",
    "    test_acc = test(model, data)\n",
    "    # output the best epoch information for model hypertuning\n",
    "    print(f\"Best Epoch: {best_epoch_info['epoch']}, \"\n",
    "          f\"Train Loss: {best_epoch_info['train_loss']:.4f}, \"\n",
    "          f\"Val Loss: {best_epoch_info['val_loss']:.4f}, \"\n",
    "          f\"Val Acc: {best_epoch_info['val_acc']:.4f}\")\n",
    "    print(f'{num_layers}-layer GCN Test Accuracy: {test_acc:.4f}')\n",
    "    return test_acc\n",
    "\n",
    "# 2, 4, 6 GCN\n",
    "print(\"Training 2-layer GCN...\")\n",
    "# after hyperparameter tuning, the best hidden_dim and learning rate are 64 and 0.005 respectively\n",
    "hidden_dim = 64\n",
    "gcn_2layer_test_acc = train_and_evaluate_gcn(data, num_layers=2, lr=0.005)\n",
    "\n",
    "print(\"Training 4-layer GCN...\")\n",
    "# after hyperparameter tuning, the best hidden_dim and learning rate are 64 and 0.005 respectively\n",
    "hidden_dim = 64\n",
    "gcn_4layer_test_acc = train_and_evaluate_gcn(data, num_layers=4, lr=0.005)\n",
    "\n",
    "print(\"Training 6-layer GCN...\")\n",
    "# after hyperparameter tuning, the best hidden_dim and learning rate are 64 and 0.01 respectively\n",
    "hidden_dim = 64\n",
    "gcn_6layer_test_acc = train_and_evaluate_gcn(data, num_layers=6, lr=0.01)\n",
    "\n",
    "# Compare the results\n",
    "print(f\"2-layer GCN Test Accuracy: {gcn_2layer_test_acc:.4f}\")\n",
    "print(f\"4-layer GCN Test Accuracy: {gcn_4layer_test_acc:.4f}\")\n",
    "print(f\"6-layer GCN Test Accuracy: {gcn_6layer_test_acc:.4f}\")\n",
    "\n",
    "# Layout\n",
    "if (gcn_2layer_test_acc > gcn_4layer_test_acc) and (gcn_2layer_test_acc > gcn_6layer_test_acc):\n",
    "    print(\"2 layer GCN performs the best. This is due to the fact that as layers increase, the model will become over-smoothing, where node representations are indistinguishable. Additionally, a 2-layer GCN effectively captures local neighborhood information without excessive complexity, making it more robust and efficient for the given task.\")\n",
    "elif (gcn_4layer_test_acc > gcn_6layer_test_acc) and (gcn_4layer_test_acc > gcn_2layer_test_acc):\n",
    "    print(\"4 layer GCN performs the best. This suggests that the dataset requires capturing higher-order neighborhood information (i.e., nodes that are further away in the graph). A 4-layer GCN strikes a good balance between capturing deeper relationships and avoiding over-smoothing or excessive computational cost.\")\n",
    "elif (gcn_6layer_test_acc > gcn_4layer_test_acc) and (gcn_6layer_test_acc > gcn_2layer_test_acc):\n",
    "    print(\"6 layer GCN performs the best. This indicates that the dataset has complex structural dependencies that require capturing information from distant nodes in the graph. However, this may also suggest that the model is less prone to over-smoothing for this specific dataset, possibly due to regularization techniques or the inherent properties of the graph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.4 Questions for Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool, global_add_pool\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN with sum readout...\n",
      "Epoch 1, Train Loss: 0.6292, Val Loss: 0.2783, Val Acc: 0.9000\n",
      "Epoch 2, Train Loss: 0.3666, Val Loss: 0.3068, Val Acc: 0.9000\n",
      "Epoch 3, Train Loss: 0.4461, Val Loss: 0.2769, Val Acc: 0.9000\n",
      "Epoch 4, Train Loss: 0.3404, Val Loss: 0.2781, Val Acc: 0.9000\n",
      "Epoch 5, Train Loss: 0.5640, Val Loss: 0.2905, Val Acc: 0.9000\n",
      "Epoch 6, Train Loss: 0.4210, Val Loss: 0.3498, Val Acc: 0.9000\n",
      "Epoch 7, Train Loss: 0.3899, Val Loss: 0.3125, Val Acc: 0.9000\n",
      "Epoch 8, Train Loss: 0.4313, Val Loss: 0.2673, Val Acc: 0.9000\n",
      "Epoch 9, Train Loss: 0.3304, Val Loss: 0.2646, Val Acc: 0.9000\n",
      "Epoch 10, Train Loss: 0.3252, Val Loss: 0.2647, Val Acc: 0.9000\n",
      "Epoch 11, Train Loss: 0.4074, Val Loss: 0.2640, Val Acc: 0.9000\n",
      "Epoch 12, Train Loss: 0.3293, Val Loss: 0.2602, Val Acc: 0.9000\n",
      "Epoch 13, Train Loss: 0.2989, Val Loss: 0.2519, Val Acc: 0.9000\n",
      "Epoch 14, Train Loss: 0.3068, Val Loss: 0.2471, Val Acc: 0.9000\n",
      "Epoch 15, Train Loss: 0.4085, Val Loss: 0.2536, Val Acc: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8p/_lylf4tn2yz39y4qkw9vg1jw0000gn/T/ipykernel_7944/318762812.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_data = torch.load('graph_data.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 0.3243, Val Loss: 0.2858, Val Acc: 0.9000\n",
      "Epoch 17, Train Loss: 0.3213, Val Loss: 0.2399, Val Acc: 0.9000\n",
      "Epoch 18, Train Loss: 0.3129, Val Loss: 0.2463, Val Acc: 0.9000\n",
      "Epoch 19, Train Loss: 0.5838, Val Loss: 0.2507, Val Acc: 0.9000\n",
      "Epoch 20, Train Loss: 0.4015, Val Loss: 0.4050, Val Acc: 0.9000\n",
      "Epoch 21, Train Loss: 0.4745, Val Loss: 0.3956, Val Acc: 0.9000\n",
      "Epoch 22, Train Loss: 0.3535, Val Loss: 0.2938, Val Acc: 0.9000\n",
      "Epoch 23, Train Loss: 0.4186, Val Loss: 0.2491, Val Acc: 0.9000\n",
      "Epoch 24, Train Loss: 0.5962, Val Loss: 0.2493, Val Acc: 0.9000\n",
      "Epoch 25, Train Loss: 0.3231, Val Loss: 0.3271, Val Acc: 0.9000\n",
      "Epoch 26, Train Loss: 0.3933, Val Loss: 0.3280, Val Acc: 0.9000\n",
      "Epoch 27, Train Loss: 0.3411, Val Loss: 0.2760, Val Acc: 0.9000\n",
      "Epoch 28, Train Loss: 0.3637, Val Loss: 0.2474, Val Acc: 0.9000\n",
      "Epoch 29, Train Loss: 0.5053, Val Loss: 0.2474, Val Acc: 0.9000\n",
      "Epoch 30, Train Loss: 0.4750, Val Loss: 0.2764, Val Acc: 0.9000\n",
      "Epoch 31, Train Loss: 0.3431, Val Loss: 0.3386, Val Acc: 0.9000\n",
      "Epoch 32, Train Loss: 0.4447, Val Loss: 0.3087, Val Acc: 0.9000\n",
      "Epoch 33, Train Loss: 0.3079, Val Loss: 0.2578, Val Acc: 0.9000\n",
      "Epoch 34, Train Loss: 0.2825, Val Loss: 0.2612, Val Acc: 0.9000\n",
      "Epoch 35, Train Loss: 0.3086, Val Loss: 0.2576, Val Acc: 0.9000\n",
      "Epoch 36, Train Loss: 0.2929, Val Loss: 0.2515, Val Acc: 0.9000\n",
      "Epoch 37, Train Loss: 0.3666, Val Loss: 0.2515, Val Acc: 0.9000\n",
      "Epoch 38, Train Loss: 0.2881, Val Loss: 0.2518, Val Acc: 0.9000\n",
      "Epoch 39, Train Loss: 0.2919, Val Loss: 0.2484, Val Acc: 0.9000\n",
      "Epoch 40, Train Loss: 0.2889, Val Loss: 0.2453, Val Acc: 0.9000\n",
      "Epoch 41, Train Loss: 0.2826, Val Loss: 0.2451, Val Acc: 0.9000\n",
      "Epoch 42, Train Loss: 0.4786, Val Loss: 0.2423, Val Acc: 0.9000\n",
      "Epoch 43, Train Loss: 0.3619, Val Loss: 0.2901, Val Acc: 0.9000\n",
      "Epoch 44, Train Loss: 0.4419, Val Loss: 0.3167, Val Acc: 0.9000\n",
      "Epoch 45, Train Loss: 0.3758, Val Loss: 0.2889, Val Acc: 0.9000\n",
      "Epoch 46, Train Loss: 0.4395, Val Loss: 0.2531, Val Acc: 0.9000\n",
      "Epoch 47, Train Loss: 0.2913, Val Loss: 0.2391, Val Acc: 0.9000\n",
      "Epoch 48, Train Loss: 0.2753, Val Loss: 0.2436, Val Acc: 0.9000\n",
      "Epoch 49, Train Loss: 0.2920, Val Loss: 0.2453, Val Acc: 0.9000\n",
      "Epoch 50, Train Loss: 0.2866, Val Loss: 0.2321, Val Acc: 0.9000\n",
      "Epoch 51, Train Loss: 0.3981, Val Loss: 0.2295, Val Acc: 0.9000\n",
      "Epoch 52, Train Loss: 0.4152, Val Loss: 0.2447, Val Acc: 0.9000\n",
      "Epoch 53, Train Loss: 0.3423, Val Loss: 0.2360, Val Acc: 0.9000\n",
      "Epoch 54, Train Loss: 0.3895, Val Loss: 0.2203, Val Acc: 0.9000\n",
      "Epoch 55, Train Loss: 0.2585, Val Loss: 0.2201, Val Acc: 0.9000\n",
      "Epoch 56, Train Loss: 0.4035, Val Loss: 0.2246, Val Acc: 0.9000\n",
      "Epoch 57, Train Loss: 0.3493, Val Loss: 0.2264, Val Acc: 0.9000\n",
      "Epoch 58, Train Loss: 0.3371, Val Loss: 0.2238, Val Acc: 0.9000\n",
      "Epoch 59, Train Loss: 0.3055, Val Loss: 0.2235, Val Acc: 0.9000\n",
      "Epoch 60, Train Loss: 0.3196, Val Loss: 0.2214, Val Acc: 0.9000\n",
      "Epoch 61, Train Loss: 0.2693, Val Loss: 0.2062, Val Acc: 0.9000\n",
      "Epoch 62, Train Loss: 0.3270, Val Loss: 0.2002, Val Acc: 0.9000\n",
      "Epoch 63, Train Loss: 0.3225, Val Loss: 0.1959, Val Acc: 0.9000\n",
      "Epoch 64, Train Loss: 0.2714, Val Loss: 0.2040, Val Acc: 0.9000\n",
      "Epoch 65, Train Loss: 0.3901, Val Loss: 0.2157, Val Acc: 0.9000\n",
      "Epoch 66, Train Loss: 0.2545, Val Loss: 0.2103, Val Acc: 0.9000\n",
      "Epoch 67, Train Loss: 0.2687, Val Loss: 0.2061, Val Acc: 0.9000\n",
      "Epoch 68, Train Loss: 0.2573, Val Loss: 0.2392, Val Acc: 0.9000\n",
      "Epoch 69, Train Loss: 0.2866, Val Loss: 0.2544, Val Acc: 0.9000\n",
      "Epoch 70, Train Loss: 0.3516, Val Loss: 0.2214, Val Acc: 0.9000\n",
      "Epoch 71, Train Loss: 0.2847, Val Loss: 0.1997, Val Acc: 0.9000\n",
      "Epoch 72, Train Loss: 0.2569, Val Loss: 0.2008, Val Acc: 0.9000\n",
      "Epoch 73, Train Loss: 0.4489, Val Loss: 0.2034, Val Acc: 0.9000\n",
      "Epoch 74, Train Loss: 0.3717, Val Loss: 0.2014, Val Acc: 0.9000\n",
      "Epoch 75, Train Loss: 0.3245, Val Loss: 0.2082, Val Acc: 0.9000\n",
      "Epoch 76, Train Loss: 0.2505, Val Loss: 0.3886, Val Acc: 0.9000\n",
      "Epoch 77, Train Loss: 0.4263, Val Loss: 0.1942, Val Acc: 0.9000\n",
      "Epoch 78, Train Loss: 0.3496, Val Loss: 0.1986, Val Acc: 0.9000\n",
      "Epoch 79, Train Loss: 0.2943, Val Loss: 0.2079, Val Acc: 0.9000\n",
      "Epoch 80, Train Loss: 0.3183, Val Loss: 0.2447, Val Acc: 0.9000\n",
      "Epoch 81, Train Loss: 0.3282, Val Loss: 0.2034, Val Acc: 0.9000\n",
      "Epoch 82, Train Loss: 0.3328, Val Loss: 0.2005, Val Acc: 0.9000\n",
      "Epoch 83, Train Loss: 0.2925, Val Loss: 0.1965, Val Acc: 0.9000\n",
      "Epoch 84, Train Loss: 0.4307, Val Loss: 0.2106, Val Acc: 0.9000\n",
      "Epoch 85, Train Loss: 0.2959, Val Loss: 0.1970, Val Acc: 0.9000\n",
      "Epoch 86, Train Loss: 0.3148, Val Loss: 0.1933, Val Acc: 0.9000\n",
      "Epoch 87, Train Loss: 0.3020, Val Loss: 0.1969, Val Acc: 0.9000\n",
      "Epoch 88, Train Loss: 0.2286, Val Loss: 0.2030, Val Acc: 0.9000\n",
      "Epoch 89, Train Loss: 0.2386, Val Loss: 0.2197, Val Acc: 0.9000\n",
      "Epoch 90, Train Loss: 0.4612, Val Loss: 0.2007, Val Acc: 0.9000\n",
      "Epoch 91, Train Loss: 0.3617, Val Loss: 0.1902, Val Acc: 0.9200\n",
      "Epoch 92, Train Loss: 0.2939, Val Loss: 0.1898, Val Acc: 0.9000\n",
      "Epoch 93, Train Loss: 0.2232, Val Loss: 0.2028, Val Acc: 0.9000\n",
      "Epoch 94, Train Loss: 0.4180, Val Loss: 0.1957, Val Acc: 0.9000\n",
      "Epoch 95, Train Loss: 0.4134, Val Loss: 0.2072, Val Acc: 0.9200\n",
      "Epoch 96, Train Loss: 0.3183, Val Loss: 0.2076, Val Acc: 0.9000\n",
      "Epoch 97, Train Loss: 0.4432, Val Loss: 0.2023, Val Acc: 0.9000\n",
      "Epoch 98, Train Loss: 0.3662, Val Loss: 0.1986, Val Acc: 0.9000\n",
      "Epoch 99, Train Loss: 0.2707, Val Loss: 0.1956, Val Acc: 0.9000\n",
      "Epoch 100, Train Loss: 0.2514, Val Loss: 0.2063, Val Acc: 0.9000\n",
      "Test Accuracy: 0.8039\n",
      "Training GCN with mean readout...\n",
      "Epoch 1, Train Loss: 0.5997, Val Loss: 0.4484, Val Acc: 0.9000\n",
      "Epoch 2, Train Loss: 0.5712, Val Loss: 0.3056, Val Acc: 0.9000\n",
      "Epoch 3, Train Loss: 0.3444, Val Loss: 0.2942, Val Acc: 0.9000\n",
      "Epoch 4, Train Loss: 0.4449, Val Loss: 0.2772, Val Acc: 0.9000\n",
      "Epoch 5, Train Loss: 0.4413, Val Loss: 0.2875, Val Acc: 0.9000\n",
      "Epoch 6, Train Loss: 0.4305, Val Loss: 0.3026, Val Acc: 0.9000\n",
      "Epoch 7, Train Loss: 0.3454, Val Loss: 0.3068, Val Acc: 0.9000\n",
      "Epoch 8, Train Loss: 0.3367, Val Loss: 0.2856, Val Acc: 0.9000\n",
      "Epoch 9, Train Loss: 0.3233, Val Loss: 0.2724, Val Acc: 0.9000\n",
      "Epoch 10, Train Loss: 0.3313, Val Loss: 0.2726, Val Acc: 0.9000\n",
      "Epoch 11, Train Loss: 0.4585, Val Loss: 0.2762, Val Acc: 0.9000\n",
      "Epoch 12, Train Loss: 0.3287, Val Loss: 0.2952, Val Acc: 0.9000\n",
      "Epoch 13, Train Loss: 0.4259, Val Loss: 0.3013, Val Acc: 0.9000\n",
      "Epoch 14, Train Loss: 0.3431, Val Loss: 0.2969, Val Acc: 0.9000\n",
      "Epoch 15, Train Loss: 0.4335, Val Loss: 0.2786, Val Acc: 0.9000\n",
      "Epoch 16, Train Loss: 0.3247, Val Loss: 0.2791, Val Acc: 0.9000\n",
      "Epoch 17, Train Loss: 0.3208, Val Loss: 0.2728, Val Acc: 0.9000\n",
      "Epoch 18, Train Loss: 0.3211, Val Loss: 0.2702, Val Acc: 0.9000\n",
      "Epoch 19, Train Loss: 0.5615, Val Loss: 0.2744, Val Acc: 0.9000\n",
      "Epoch 20, Train Loss: 0.4973, Val Loss: 0.3240, Val Acc: 0.9000\n",
      "Epoch 21, Train Loss: 0.3810, Val Loss: 0.3702, Val Acc: 0.9000\n",
      "Epoch 22, Train Loss: 0.3906, Val Loss: 0.3459, Val Acc: 0.9000\n",
      "Epoch 23, Train Loss: 0.4312, Val Loss: 0.2943, Val Acc: 0.9000\n",
      "Epoch 24, Train Loss: 0.3127, Val Loss: 0.2711, Val Acc: 0.9000\n",
      "Epoch 25, Train Loss: 0.4689, Val Loss: 0.2691, Val Acc: 0.9000\n",
      "Epoch 26, Train Loss: 0.3261, Val Loss: 0.2776, Val Acc: 0.9000\n",
      "Epoch 27, Train Loss: 0.4150, Val Loss: 0.2860, Val Acc: 0.9000\n",
      "Epoch 28, Train Loss: 0.3263, Val Loss: 0.2925, Val Acc: 0.9000\n",
      "Epoch 29, Train Loss: 0.4203, Val Loss: 0.2802, Val Acc: 0.9000\n",
      "Epoch 30, Train Loss: 0.4009, Val Loss: 0.2782, Val Acc: 0.9000\n",
      "Epoch 31, Train Loss: 0.3093, Val Loss: 0.2757, Val Acc: 0.9000\n",
      "Epoch 32, Train Loss: 0.3094, Val Loss: 0.2689, Val Acc: 0.9000\n",
      "Epoch 33, Train Loss: 0.2996, Val Loss: 0.2657, Val Acc: 0.9000\n",
      "Epoch 34, Train Loss: 0.4288, Val Loss: 0.2655, Val Acc: 0.9000\n",
      "Epoch 35, Train Loss: 0.4231, Val Loss: 0.2873, Val Acc: 0.9000\n",
      "Epoch 36, Train Loss: 0.4154, Val Loss: 0.3251, Val Acc: 0.9000\n",
      "Epoch 37, Train Loss: 0.4043, Val Loss: 0.3182, Val Acc: 0.9000\n",
      "Epoch 38, Train Loss: 0.3287, Val Loss: 0.2866, Val Acc: 0.9000\n",
      "Epoch 39, Train Loss: 0.2909, Val Loss: 0.2619, Val Acc: 0.9000\n",
      "Epoch 40, Train Loss: 0.2961, Val Loss: 0.2637, Val Acc: 0.9000\n",
      "Epoch 41, Train Loss: 0.3027, Val Loss: 0.2616, Val Acc: 0.9000\n",
      "Epoch 42, Train Loss: 0.3001, Val Loss: 0.2592, Val Acc: 0.9000\n",
      "Epoch 43, Train Loss: 0.2902, Val Loss: 0.2615, Val Acc: 0.9000\n",
      "Epoch 44, Train Loss: 0.2988, Val Loss: 0.2632, Val Acc: 0.9000\n",
      "Epoch 45, Train Loss: 0.2934, Val Loss: 0.2597, Val Acc: 0.9000\n",
      "Epoch 46, Train Loss: 0.3963, Val Loss: 0.2572, Val Acc: 0.9000\n",
      "Epoch 47, Train Loss: 0.3018, Val Loss: 0.2600, Val Acc: 0.9000\n",
      "Epoch 48, Train Loss: 0.2893, Val Loss: 0.2554, Val Acc: 0.9000\n",
      "Epoch 49, Train Loss: 0.3544, Val Loss: 0.2519, Val Acc: 0.9000\n",
      "Epoch 50, Train Loss: 0.2876, Val Loss: 0.2551, Val Acc: 0.9000\n",
      "Epoch 51, Train Loss: 0.2786, Val Loss: 0.2523, Val Acc: 0.9000\n",
      "Epoch 52, Train Loss: 0.2846, Val Loss: 0.2493, Val Acc: 0.9000\n",
      "Epoch 53, Train Loss: 0.2937, Val Loss: 0.2478, Val Acc: 0.9000\n",
      "Epoch 54, Train Loss: 0.2946, Val Loss: 0.2451, Val Acc: 0.9000\n",
      "Epoch 55, Train Loss: 0.2917, Val Loss: 0.2429, Val Acc: 0.9000\n",
      "Epoch 56, Train Loss: 0.3045, Val Loss: 0.2430, Val Acc: 0.9000\n",
      "Epoch 57, Train Loss: 0.2717, Val Loss: 0.2424, Val Acc: 0.9000\n",
      "Epoch 58, Train Loss: 0.2918, Val Loss: 0.2382, Val Acc: 0.9000\n",
      "Epoch 59, Train Loss: 0.2747, Val Loss: 0.2368, Val Acc: 0.9000\n",
      "Epoch 60, Train Loss: 0.2853, Val Loss: 0.2360, Val Acc: 0.9000\n",
      "Epoch 61, Train Loss: 0.2926, Val Loss: 0.2353, Val Acc: 0.9000\n",
      "Epoch 62, Train Loss: 0.3286, Val Loss: 0.2322, Val Acc: 0.9000\n",
      "Epoch 63, Train Loss: 0.3188, Val Loss: 0.2334, Val Acc: 0.9000\n",
      "Epoch 64, Train Loss: 0.3072, Val Loss: 0.2298, Val Acc: 0.9000\n",
      "Epoch 65, Train Loss: 0.2719, Val Loss: 0.2411, Val Acc: 0.9000\n",
      "Epoch 66, Train Loss: 0.3337, Val Loss: 0.2343, Val Acc: 0.9000\n",
      "Epoch 67, Train Loss: 0.3449, Val Loss: 0.2407, Val Acc: 0.9000\n",
      "Epoch 68, Train Loss: 0.3658, Val Loss: 0.2678, Val Acc: 0.9000\n",
      "Epoch 69, Train Loss: 0.4464, Val Loss: 0.2317, Val Acc: 0.9000\n",
      "Epoch 70, Train Loss: 0.2798, Val Loss: 0.2275, Val Acc: 0.9000\n",
      "Epoch 71, Train Loss: 0.2541, Val Loss: 0.2338, Val Acc: 0.9000\n",
      "Epoch 72, Train Loss: 0.2714, Val Loss: 0.2327, Val Acc: 0.9000\n",
      "Epoch 73, Train Loss: 0.4181, Val Loss: 0.2355, Val Acc: 0.9000\n",
      "Epoch 74, Train Loss: 0.3261, Val Loss: 0.2531, Val Acc: 0.9000\n",
      "Epoch 75, Train Loss: 0.3043, Val Loss: 0.2241, Val Acc: 0.9000\n",
      "Epoch 76, Train Loss: 0.3681, Val Loss: 0.2423, Val Acc: 0.9000\n",
      "Epoch 77, Train Loss: 0.2805, Val Loss: 0.2249, Val Acc: 0.9000\n",
      "Epoch 78, Train Loss: 0.3243, Val Loss: 0.2282, Val Acc: 0.9000\n",
      "Epoch 79, Train Loss: 0.2908, Val Loss: 0.2335, Val Acc: 0.9000\n",
      "Epoch 80, Train Loss: 0.4215, Val Loss: 0.2270, Val Acc: 0.9000\n",
      "Epoch 81, Train Loss: 0.4175, Val Loss: 0.2333, Val Acc: 0.9000\n",
      "Epoch 82, Train Loss: 0.3224, Val Loss: 0.2328, Val Acc: 0.9000\n",
      "Epoch 83, Train Loss: 0.3654, Val Loss: 0.2208, Val Acc: 0.9000\n",
      "Epoch 84, Train Loss: 0.2578, Val Loss: 0.2240, Val Acc: 0.9000\n",
      "Epoch 85, Train Loss: 0.5634, Val Loss: 0.2180, Val Acc: 0.9000\n",
      "Epoch 86, Train Loss: 0.2843, Val Loss: 0.2498, Val Acc: 0.9000\n",
      "Epoch 87, Train Loss: 0.3232, Val Loss: 0.2371, Val Acc: 0.9000\n",
      "Epoch 88, Train Loss: 0.2678, Val Loss: 0.2185, Val Acc: 0.9000\n",
      "Epoch 89, Train Loss: 0.2652, Val Loss: 0.2431, Val Acc: 0.9000\n",
      "Epoch 90, Train Loss: 0.2867, Val Loss: 0.2537, Val Acc: 0.9000\n",
      "Epoch 91, Train Loss: 0.5718, Val Loss: 0.2203, Val Acc: 0.9000\n",
      "Epoch 92, Train Loss: 0.2980, Val Loss: 0.2533, Val Acc: 0.9000\n",
      "Epoch 93, Train Loss: 0.3615, Val Loss: 0.2560, Val Acc: 0.9000\n",
      "Epoch 94, Train Loss: 0.4070, Val Loss: 0.2271, Val Acc: 0.9000\n",
      "Epoch 95, Train Loss: 0.3477, Val Loss: 0.2174, Val Acc: 0.9000\n",
      "Epoch 96, Train Loss: 0.2777, Val Loss: 0.2217, Val Acc: 0.9000\n",
      "Epoch 97, Train Loss: 0.2560, Val Loss: 0.2295, Val Acc: 0.9000\n",
      "Epoch 98, Train Loss: 0.3436, Val Loss: 0.2222, Val Acc: 0.9000\n",
      "Epoch 99, Train Loss: 0.2948, Val Loss: 0.2105, Val Acc: 0.9000\n",
      "Epoch 100, Train Loss: 0.2727, Val Loss: 0.2106, Val Acc: 0.9000\n",
      "Test Accuracy: 0.7333\n",
      "Training GCN with max readout...\n",
      "Epoch 1, Train Loss: 0.6122, Val Loss: 0.4773, Val Acc: 0.9000\n",
      "Epoch 2, Train Loss: 0.4032, Val Loss: 0.2795, Val Acc: 0.9000\n",
      "Epoch 3, Train Loss: 0.5065, Val Loss: 0.2774, Val Acc: 0.9000\n",
      "Epoch 4, Train Loss: 0.3478, Val Loss: 0.2766, Val Acc: 0.9000\n",
      "Epoch 5, Train Loss: 0.4290, Val Loss: 0.2988, Val Acc: 0.9000\n",
      "Epoch 6, Train Loss: 0.3454, Val Loss: 0.3035, Val Acc: 0.9000\n",
      "Epoch 7, Train Loss: 0.3325, Val Loss: 0.2773, Val Acc: 0.9000\n",
      "Epoch 8, Train Loss: 0.3164, Val Loss: 0.2646, Val Acc: 0.9000\n",
      "Epoch 9, Train Loss: 0.3163, Val Loss: 0.2620, Val Acc: 0.9000\n",
      "Epoch 10, Train Loss: 0.4511, Val Loss: 0.2602, Val Acc: 0.9000\n",
      "Epoch 11, Train Loss: 0.3233, Val Loss: 0.2783, Val Acc: 0.9000\n",
      "Epoch 12, Train Loss: 0.3293, Val Loss: 0.2787, Val Acc: 0.9000\n",
      "Epoch 13, Train Loss: 0.4136, Val Loss: 0.2643, Val Acc: 0.9000\n",
      "Epoch 14, Train Loss: 0.3176, Val Loss: 0.2576, Val Acc: 0.9000\n",
      "Epoch 15, Train Loss: 0.4151, Val Loss: 0.2513, Val Acc: 0.9000\n",
      "Epoch 16, Train Loss: 0.3992, Val Loss: 0.2677, Val Acc: 0.9000\n",
      "Epoch 17, Train Loss: 0.4748, Val Loss: 0.2819, Val Acc: 0.9000\n",
      "Epoch 18, Train Loss: 0.4416, Val Loss: 0.3030, Val Acc: 0.9000\n",
      "Epoch 19, Train Loss: 0.3551, Val Loss: 0.2891, Val Acc: 0.9000\n",
      "Epoch 20, Train Loss: 0.3099, Val Loss: 0.2368, Val Acc: 0.9000\n",
      "Epoch 21, Train Loss: 0.8308, Val Loss: 0.2288, Val Acc: 0.9000\n",
      "Epoch 22, Train Loss: 0.3215, Val Loss: 0.2828, Val Acc: 0.9000\n",
      "Epoch 23, Train Loss: 0.5134, Val Loss: 0.3138, Val Acc: 0.9000\n",
      "Epoch 24, Train Loss: 0.3738, Val Loss: 0.3220, Val Acc: 0.9000\n",
      "Epoch 25, Train Loss: 0.3513, Val Loss: 0.2707, Val Acc: 0.9000\n",
      "Epoch 26, Train Loss: 0.4138, Val Loss: 0.2329, Val Acc: 0.9000\n",
      "Epoch 27, Train Loss: 0.3041, Val Loss: 0.2276, Val Acc: 0.9000\n",
      "Epoch 28, Train Loss: 0.3062, Val Loss: 0.2266, Val Acc: 0.9000\n",
      "Epoch 29, Train Loss: 0.4171, Val Loss: 0.2253, Val Acc: 0.9000\n",
      "Epoch 30, Train Loss: 0.3181, Val Loss: 0.2307, Val Acc: 0.9000\n",
      "Epoch 31, Train Loss: 0.3045, Val Loss: 0.2299, Val Acc: 0.9000\n",
      "Epoch 32, Train Loss: 0.3793, Val Loss: 0.2278, Val Acc: 0.9000\n",
      "Epoch 33, Train Loss: 0.3146, Val Loss: 0.2265, Val Acc: 0.9000\n",
      "Epoch 34, Train Loss: 0.2981, Val Loss: 0.2231, Val Acc: 0.9000\n",
      "Epoch 35, Train Loss: 0.2929, Val Loss: 0.2203, Val Acc: 0.9000\n",
      "Epoch 36, Train Loss: 0.3715, Val Loss: 0.2204, Val Acc: 0.9000\n",
      "Epoch 37, Train Loss: 0.2946, Val Loss: 0.2223, Val Acc: 0.9000\n",
      "Epoch 38, Train Loss: 0.2873, Val Loss: 0.2236, Val Acc: 0.9000\n",
      "Epoch 39, Train Loss: 0.2844, Val Loss: 0.2237, Val Acc: 0.9000\n",
      "Epoch 40, Train Loss: 0.2949, Val Loss: 0.2264, Val Acc: 0.9000\n",
      "Epoch 41, Train Loss: 0.2920, Val Loss: 0.2252, Val Acc: 0.9000\n",
      "Epoch 42, Train Loss: 0.2863, Val Loss: 0.2232, Val Acc: 0.9000\n",
      "Epoch 43, Train Loss: 0.2875, Val Loss: 0.2185, Val Acc: 0.9000\n",
      "Epoch 44, Train Loss: 0.2817, Val Loss: 0.2152, Val Acc: 0.9000\n",
      "Epoch 45, Train Loss: 0.3805, Val Loss: 0.2131, Val Acc: 0.9000\n",
      "Epoch 46, Train Loss: 0.3517, Val Loss: 0.2143, Val Acc: 0.9000\n",
      "Epoch 47, Train Loss: 0.3097, Val Loss: 0.2110, Val Acc: 0.9000\n",
      "Epoch 48, Train Loss: 0.2704, Val Loss: 0.2132, Val Acc: 0.9000\n",
      "Epoch 49, Train Loss: 0.2757, Val Loss: 0.2222, Val Acc: 0.9000\n",
      "Epoch 50, Train Loss: 0.2808, Val Loss: 0.2159, Val Acc: 0.9000\n",
      "Epoch 51, Train Loss: 0.3583, Val Loss: 0.2102, Val Acc: 0.9000\n",
      "Epoch 52, Train Loss: 0.2491, Val Loss: 0.2141, Val Acc: 0.9000\n",
      "Epoch 53, Train Loss: 0.3097, Val Loss: 0.2165, Val Acc: 0.9000\n",
      "Epoch 54, Train Loss: 0.4304, Val Loss: 0.2240, Val Acc: 0.9000\n",
      "Epoch 55, Train Loss: 0.2617, Val Loss: 0.2111, Val Acc: 0.9000\n",
      "Epoch 56, Train Loss: 0.3893, Val Loss: 0.2083, Val Acc: 0.9000\n",
      "Epoch 57, Train Loss: 0.2793, Val Loss: 0.2079, Val Acc: 0.9000\n",
      "Epoch 58, Train Loss: 0.2590, Val Loss: 0.2193, Val Acc: 0.9000\n",
      "Epoch 59, Train Loss: 0.2612, Val Loss: 0.2251, Val Acc: 0.9000\n",
      "Epoch 60, Train Loss: 0.3472, Val Loss: 0.2132, Val Acc: 0.9000\n",
      "Epoch 61, Train Loss: 0.3257, Val Loss: 0.2230, Val Acc: 0.9000\n",
      "Epoch 62, Train Loss: 0.2727, Val Loss: 0.2230, Val Acc: 0.9000\n",
      "Epoch 63, Train Loss: 0.2434, Val Loss: 0.2452, Val Acc: 0.9000\n",
      "Epoch 64, Train Loss: 0.2752, Val Loss: 0.2425, Val Acc: 0.9000\n",
      "Epoch 65, Train Loss: 0.4442, Val Loss: 0.2187, Val Acc: 0.9000\n",
      "Epoch 66, Train Loss: 0.2734, Val Loss: 0.2160, Val Acc: 0.9000\n",
      "Epoch 67, Train Loss: 0.3733, Val Loss: 0.1985, Val Acc: 0.9000\n",
      "Epoch 68, Train Loss: 0.2471, Val Loss: 0.1980, Val Acc: 0.9000\n",
      "Epoch 69, Train Loss: 0.2366, Val Loss: 0.2012, Val Acc: 0.9000\n",
      "Epoch 70, Train Loss: 0.2441, Val Loss: 0.2033, Val Acc: 0.9000\n",
      "Epoch 71, Train Loss: 0.2280, Val Loss: 0.2071, Val Acc: 0.9000\n",
      "Epoch 72, Train Loss: 0.2313, Val Loss: 0.2126, Val Acc: 0.9000\n",
      "Epoch 73, Train Loss: 0.3196, Val Loss: 0.2172, Val Acc: 0.9200\n",
      "Epoch 74, Train Loss: 0.3042, Val Loss: 0.2316, Val Acc: 0.9600\n",
      "Epoch 75, Train Loss: 0.3188, Val Loss: 0.2250, Val Acc: 0.9000\n",
      "Epoch 76, Train Loss: 0.2229, Val Loss: 0.2272, Val Acc: 0.9000\n",
      "Epoch 77, Train Loss: 0.2176, Val Loss: 0.2273, Val Acc: 0.9000\n",
      "Epoch 78, Train Loss: 0.3339, Val Loss: 0.2395, Val Acc: 0.9400\n",
      "Epoch 79, Train Loss: 0.2667, Val Loss: 0.2400, Val Acc: 0.9400\n",
      "Epoch 80, Train Loss: 0.3152, Val Loss: 0.2448, Val Acc: 0.9200\n",
      "Epoch 81, Train Loss: 0.2241, Val Loss: 0.2483, Val Acc: 0.9400\n",
      "Epoch 82, Train Loss: 0.2134, Val Loss: 0.2443, Val Acc: 0.8800\n",
      "Epoch 83, Train Loss: 0.2032, Val Loss: 0.2632, Val Acc: 0.9000\n",
      "Epoch 84, Train Loss: 0.4197, Val Loss: 0.2451, Val Acc: 0.8800\n",
      "Epoch 85, Train Loss: 0.2055, Val Loss: 0.2763, Val Acc: 0.9000\n",
      "Epoch 86, Train Loss: 0.2559, Val Loss: 0.2343, Val Acc: 0.9000\n",
      "Epoch 87, Train Loss: 0.2236, Val Loss: 0.2566, Val Acc: 0.9000\n",
      "Epoch 88, Train Loss: 0.2243, Val Loss: 0.2290, Val Acc: 0.9000\n",
      "Epoch 89, Train Loss: 0.2278, Val Loss: 0.2414, Val Acc: 0.9000\n",
      "Epoch 90, Train Loss: 0.2218, Val Loss: 0.2340, Val Acc: 0.9000\n",
      "Epoch 91, Train Loss: 0.5121, Val Loss: 0.2393, Val Acc: 0.8800\n",
      "Epoch 92, Train Loss: 0.2499, Val Loss: 0.2769, Val Acc: 0.9000\n",
      "Epoch 93, Train Loss: 0.2602, Val Loss: 0.2399, Val Acc: 0.8800\n",
      "Epoch 94, Train Loss: 0.3665, Val Loss: 0.2463, Val Acc: 0.8800\n",
      "Epoch 95, Train Loss: 0.3187, Val Loss: 0.2397, Val Acc: 0.8800\n",
      "Epoch 96, Train Loss: 0.2616, Val Loss: 0.2547, Val Acc: 0.9200\n",
      "Epoch 97, Train Loss: 0.3359, Val Loss: 0.2613, Val Acc: 0.9200\n",
      "Epoch 98, Train Loss: 0.3557, Val Loss: 0.2413, Val Acc: 0.8800\n",
      "Epoch 99, Train Loss: 0.2121, Val Loss: 0.2410, Val Acc: 0.8800\n",
      "Epoch 100, Train Loss: 0.2087, Val Loss: 0.2371, Val Acc: 0.8800\n",
      "Test Accuracy: 0.7098\n",
      "sum readout Test Accuracy: 0.8039\n",
      "mean readout Test Accuracy: 0.7333\n",
      "max readout Test Accuracy: 0.7098\n",
      "The best readout function is sum with accuracy 0.8039.\n",
      "Sum keeps the information of all nodes, it avoids information loss. Compared to Average and Max, Sum is better at capturing global features.\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "graph_data = torch.load('graph_data.pt')\n",
    "\n",
    "# split\n",
    "train_data = graph_data[:100]  # first 100 as training set\n",
    "val_data = graph_data[100:150]  # 101 to 150 as validation set\n",
    "test_data = graph_data[150:]  # rest as test set\n",
    "\n",
    "# GCN + READOUT + MLP\n",
    "class GCNWithReadout(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, readout_type='sum'):\n",
    "        super(GCNWithReadout, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.readout_type = readout_type\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # GCN \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # READOUT \n",
    "        if self.readout_type == 'sum':\n",
    "            x = global_add_pool(x, batch)\n",
    "        elif self.readout_type == 'mean':\n",
    "            x = global_mean_pool(x, batch)\n",
    "        elif self.readout_type == 'max':\n",
    "            x = global_max_pool(x, batch)\n",
    "\n",
    "        # MLP \n",
    "        x = self.mlp(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# train function\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# validate function\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item()\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += int((pred == data.y).sum())\n",
    "            # print(\"correct:\", correct)\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "# test function\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    # print(\"Testing...\")\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "# train and evaluate function\n",
    "def train_and_evaluate(model, train_data, val_data, test_data, epochs=100, lr=0.01):\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    best_val_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict()\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    # load the best model and evaluate on the test set\n",
    "    model.load_state_dict(best_model)\n",
    "    test_acc = test(model, test_loader)\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    return test_acc\n",
    "\n",
    "# initialization\n",
    "input_dim = train_data[0].num_features  # node feature dim\n",
    "hidden_dim = 32  # hidden dim\n",
    "output_dim = torch.unique(torch.cat([data.y for data in graph_data])).size(0)  # num of classes\n",
    "\n",
    "# 3 readout\n",
    "readout_types = ['sum', 'mean', 'max']\n",
    "results = {}\n",
    "\n",
    "for readout_type in readout_types:\n",
    "    print(f\"Training GCN with {readout_type} readout...\")\n",
    "    model = GCNWithReadout(input_dim, hidden_dim, output_dim, readout_type=readout_type)\n",
    "    test_acc = train_and_evaluate(model, train_data, val_data, test_data)\n",
    "    results[readout_type] = test_acc\n",
    "\n",
    "for readout_type, acc in results.items():\n",
    "    print(f\"{readout_type} readout Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "best_readout = max(results, key=results.get)\n",
    "print(f\"The best readout function is {best_readout} with accuracy {results[best_readout]:.4f}.\")\n",
    "\n",
    "if best_readout == 'sum':\n",
    "    print(\"Sum keeps the information of all nodes, it avoids information loss. Compared to Average and Max, Sum is better at capturing global features.\")\n",
    "elif best_readout == 'mean':\n",
    "    print(\"Mean smooths out the differences between node features and reduces the impact of noise\")\n",
    "elif best_readout == 'max':\n",
    "    print(\"Max focuses on capturing the most salient features of the graph (i.e. the node information that stands out the most). This method is very effective when the key information of the graph is concentrated in a few nodes, and interference from irrelevant or secondary nodes can be ignored\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
